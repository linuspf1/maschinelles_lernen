{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendung von maschinellem Lernen auf den KHK_Klassifikation.csv Datensatz\n",
    "\n",
    "## Praktische Demonstration für verschiedene machine Learning Modelle\n",
    "\n",
    "### Tim Bleicher, Linus Pfeifer\n",
    "\n",
    "Dieses Jupyter Notebook demonstriert die Anwendung von verschiedenen Machine Learning Modellen auf den KHK_Klassifikation.csv Datensatz. \n",
    "\n",
    "# Inhaltsverzeichnis\n",
    "\n",
    "## 1. Einbindung der Daten\n",
    "- **1.1 Explorative Analyse der Daten**\n",
    "\n",
    "## 2. PCA-Dimensionsreduzierung zur Visualisierung und Analyse der Daten\n",
    "- **Funktionsweise von PCA**\n",
    "- **Lässt sich aus den PCA-Daten eine potentielle gute Separierbarkeit der Klassen ablesen?**\n",
    "\n",
    "## 3. Anwendung verschiedener Klassifikationsverfahren\n",
    "- **Definition und Datenvorbereitung**\n",
    "- **3.1 Logistische Regression**\n",
    "  - 3.1.1 Modell definieren und trainieren\n",
    "  - 3.1.2 Modell testen\n",
    "- **3.2 Entscheidungsbäume**\n",
    "  - 3.2.1 Klassische Entscheidungsbäume\n",
    "  - 3.2.2 Bagging in Form von Random Forest\n",
    "  - 3.2.3 Boosting in Form von AdaBoost\n",
    "  - 3.2.4 Stacking\n",
    "- **3.3 k-Nearest-Neighbor**\n",
    "  - 3.3.1 k-Nearest-Neighbor mit euklidischer Metrik\n",
    "  - 3.3.2 k-Nearest-Neighbor mit Manhattan Metrik\n",
    "  - 3.3.3 k-Nearest-Neighbor mit Minkowski Metrik (p = 3)\n",
    "- **3.4 Support Vector Machine**\n",
    "- **3.5 Neuronales Netz**\n",
    "\n",
    "## 4. Bedeutung der einzelnen Features\n",
    "- **4.1 Feature-Bedeutung von PCA**\n",
    "- **4.2 Feature-Bedeutung für Random Forest**\n",
    "- **4.3 Feature-Bedeutung für SVM**\n",
    "\n",
    "## 5. Feature-Engineering\n",
    "- **5.1 Generieren der PCA-Hauptkomponenten-Daten**\n",
    "- **5.2 Testen des Feature-Engineering auf k-Nearest-Neighbor mit Manhattan Metrik**\n",
    "- **5.3 Testen des Feature-Engineering auf einem klassischen Entscheidungsbaum**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einbindung der Daten\n",
    "\n",
    "Zu beginn des Projekts werden die Daten zunächst geladen um diese im anschluss analysieren und nutzen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('KHK_Klassifikation.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 explorative Analyse der Daten \n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA-Dimensionsreduzierung zur Visualisierung und Analyse der Daten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionsweise von PCA\n",
    "Die Hauptkomponentenanalyse (PCA) dient der Dimensionsreduktion eines Datensatzes. Dies ermöglicht beispielsweise verschiedene Analyse des gesamten Datensatzes (mit mehr als 3 Dimensionen), wobei die Ergebnisse durch die Dimensionsreduktion weiterhin visualisiert werden können.\n",
    "Das Verfahren der PCA läuft nach folgendem Schema ab:\n",
    "\n",
    "1. Berechnung des Mittelwerts und Zentrierung der Daten\n",
    "2. Berechnung der Kovarianzmatrix\n",
    "3. Berechnung der Eigenwerte und Eigenvektoren\n",
    "4. Transformation der Daten\n",
    "\n",
    "Damit die PCA korrekt funktioniert, muss zunächst von jeder Dimension der Mittelwert subtrahiert werden. Dieser Mittelwert entspricht dem Durchschnittswert jeder Dimension. Beispielsweise wird von allen $x$-Werten der Mittelwert $\\overline{x}$ subtrahiert. Entsprechendes gilt für die anderen Dimensionen der Daten. Dadurch entsteht ein Datensatz mit einem Mittelwert von null.\n",
    "\n",
    "Im nächsten Schritt wird die Kovarianzmatrix berechnet, welche die wechselseitigen Zusammenhänge zwischen den Merkmalen quantifiziert. Falls zwei Merkmale stark korrelieren, können diese in einer neuen Achse kombiniert werden.\n",
    "\n",
    "Anschließend werden die Eigenwerte und Eigenvektoren der Kovarianzmatrix bestimmt. Die Eigenvektoren definieren die Richtungen der Hauptkomponenten, während die zugehörigen Eigenwerte die Bedeutung bzw. die Varianz der jeweiligen Eigenvektoren widerspiegeln.\n",
    "\n",
    "Es folgt die eigentliche Dimensionsreduktion, indem nur diejenigen Eigenvektoren mit den größten Eigenwerten ausgewählt werden. Diese Eigenvektoren entsprechen den neuen Hauptachsen des Datensatzes.\n",
    "\n",
    "Schließlich werden die Daten transformiert, indem die ursprüngliche Datenmatrix mit der Matrix der Eigenvektoren multipliziert wird. In dieser Matrix repräsentiert jede Spalte einen Eigenvektor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['Geschlecht', 'EKG', 'AP']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    # Encode categorical columns\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target variable \"KHK\" before scaling\n",
    "data_without_target = data.drop(columns=[\"KHK\"], errors=\"ignore\")\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_without_target)\n",
    "\n",
    "# PCA transformation with two principal components\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Convert the PCA results into a DataFrame\n",
    "df_pca = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Interactive visualization\n",
    "fig = px.scatter(df_pca, x='PC1', y='PC2', title='PCA Visualization of the Data', opacity=0.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lässt sich aus den PCA-Daten eine potentielle gute Separierbarkeit der Klassen ablesen? \n",
    "TODO\n",
    "--> Ich würde sagen nein, lass aber mal drüber quatschen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anwendung verschiedener vorgestellter Klassifikationsverfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition und Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical columns\n",
    "categorical_features = [\"Geschlecht\", \"EKG\", \"AP\"]\n",
    "numerical_features = [\"Alter\", \"Blutdruck\", \"Chol\", \"Blutzucker\", \"HFmax\", \"RZ\"]\n",
    "\n",
    "# Select target variable and features\n",
    "X = data[categorical_features + numerical_features].copy()\n",
    "y = data[\"KHK\"]\n",
    "\n",
    "# Reorder features to match the desired order\n",
    "desired_order = [\"Alter\", \"Geschlecht\", \"Blutdruck\", \"Chol\", \"Blutzucker\", \"EKG\", \"HFmax\", \"AP\", \"RZ\"]\n",
    "X = X[desired_order]\n",
    "\n",
    "# Apply Label Encoding to categorical features\n",
    "label_encoders = {}  # Store LabelEncoder objects\n",
    "for col in categorical_features:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 logistische Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Modell definieren und trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression for binary classification\n",
    "\n",
    "# Create pipeline with preprocessing and logistic regression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Modell testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_log_reg = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "classification_rep = classification_report(y_test, y_pred_log_reg)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Entscheidungsbäume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 klassische Entscheidungsbäume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modellgenauigkeit: 0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59        77\n",
      "           1       0.70      0.64      0.67       107\n",
      "\n",
      "    accuracy                           0.64       184\n",
      "   macro avg       0.63      0.63      0.63       184\n",
      "weighted avg       0.64      0.64      0.64       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Decision Tree Classifier\n",
    "clf_tree = DecisionTreeClassifier(random_state=42)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_tree = clf_tree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "classification_rep_tree = classification_report(y_test, y_pred_tree)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_tree:.2f}\")\n",
    "print(classification_rep_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Bagging in Form von Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_random_forest = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "classification_rep = classification_report(y_test, y_pred_random_forest)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_random_forest:.2f}\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Boosting in Form von AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Train AdaBoost model with specified parameters\n",
    "adaboost_model = AdaBoostClassifier(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ada = adaboost_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_ada)  # Note: variable name might be misleading\n",
    "classification_rep = classification_report(y_test, y_pred_ada)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_random_forest:.2f}\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base models: KNN, SVM, and Logistic Regression\n",
    "base_estimators = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),  # KNN with 5 neighbors\n",
    "    ('svc', SVC(kernel='linear', random_state=42)),  # SVM with a linear kernel\n",
    "    ('logreg', LogisticRegression(random_state=42))  # Logistic Regression\n",
    "]\n",
    "\n",
    "# Final model (meta-model)\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# Create StackingClassifier with base models and final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_estimators, final_estimator=final_estimator)\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_stack = accuracy_score(y_test, y_pred_stack)\n",
    "classification_rep = classification_report(y_test, y_pred_stack)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_stack:.2f}\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 k-Nearest-Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 k-Nearest-Neighbor mit euklidischer Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 and Euclidean distance metric\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10, metric='euclidean')\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "classification_rep_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_knn:.2f}\")\n",
    "print(classification_rep_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 k-Nearest-Neighbor mit manhattan Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modellgenauigkeit: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.77        77\n",
      "           1       0.89      0.73      0.80       107\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.79      0.80      0.79       184\n",
      "weighted avg       0.81      0.79      0.79       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create k-NN model with k=10 and Manhattan distance metric\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10, metric='manhattan')\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "classification_rep_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_knn:.2f}\")\n",
    "print(classification_rep_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 k-Nearest-Neighbor mit Minkowski Metrik und p = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 and Minkowski distance metric (p=3)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10, metric='minkowski', p=3)\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "classification_rep_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_knn:.2f}\")\n",
    "print(classification_rep_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM model with a linear kernel\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_svm:.2f}\")\n",
    "print(classification_rep_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Neuronales Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer):\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer\n",
    "        Dense(32, activation='relu'),  # Second hidden layer\n",
    "        Dense(16, activation='relu'),  # Third hidden layer\n",
    "        Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,  # Set optimizer\n",
    "                  loss='binary_crossentropy',  # Loss function for binary classification\n",
    "                  metrics=['accuracy'])  # Metrics to track during training\n",
    "\n",
    "    # Display model summary\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using SGD optimizer\n",
    "sgd_model = create_model(optimizer='sgd')\n",
    "\n",
    "# Train the model\n",
    "history_sgd = sgd_model.fit(X_train, y_train,\n",
    "                            epochs=50,  # Number of epochs for training\n",
    "                            batch_size=32,  # Batch size for training\n",
    "                            validation_split=0.2,  # Split of training data for validation\n",
    "                            verbose=1)  # Display progress during training\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_sgd, test_accuracy_sgd = sgd_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Visualize training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_sgd.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_sgd.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_sgd.history['loss'], label='Training Loss')\n",
    "plt.plot(history_sgd.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "y_pred_classes_sgd = (y_pred_sgd > 0.5).astype(int)  # Convert probabilities to binary classes\n",
    "\n",
    "# Confusion Matrix and\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using Adam optimizer\n",
    "adam_model = create_model(optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "history_adam = adam_model.fit(X_train, y_train,\n",
    "                              epochs=50,  # Number of epochs for training\n",
    "                              batch_size=32,  # Batch size for training\n",
    "                              validation_split=0.2,  # Split of training data for validation\n",
    "                              verbose=1)  # Display progress during training\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy_adam = adam_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Visualize training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_adam.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_adam.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_adam.history['loss'], label='Training Loss')\n",
    "plt.plot(history_adam.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_adam = adam_model.predict(X_test)\n",
    "y_pred_classes_adam = (y_pred_adam > 0.5).astype(int)  # Convert probabilities to binary classes\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(f\"\\nTest Accuracy: {test_accuracy_adam:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes_adam))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bedeutung der einzelnen Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature-Bedeutung von PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names (excluding the target variable \"KHK\")\n",
    "feature_names = data.columns.tolist()\n",
    "feature_names.remove(\"KHK\")\n",
    "\n",
    "# Compute the importance of features from PCA components\n",
    "feature_importance = np.abs(pca.components_).sum(axis=0)\n",
    "\n",
    "# Create DataFrame for Plotly visualization\n",
    "df_plot = pd.DataFrame({\"Feature\": feature_names, \"Wichtigkeit\": feature_importance})\n",
    "\n",
    "# Create an interactive bar plot with Plotly\n",
    "fig = px.bar(df_plot, x=\"Feature\", y=\"Wichtigkeit\", title=\"Feature Importance from PCA\", labels={\"Feature\": \"Feature\", \"Wichtigkeit\": \"Feature Importance\"})\n",
    "fig.update_xaxes()  # Update x-axis for better readability\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature-Bedeutung für Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importance from the Random Forest model\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Create DataFrame for Plotly visualization\n",
    "df_plot = pd.DataFrame({\"Feature\": X.columns.tolist(), \"Wichtigkeit\": feature_importance})\n",
    "\n",
    "# Create an interactive bar plot with Plotly\n",
    "fig = px.bar(df_plot, x=\"Feature\", y=\"Wichtigkeit\", title=\"Feature Importance from Random Forest\", labels={\"Feature\": \"Feature\", \"Wichtigkeit\": \"Feature Importance\"})\n",
    "fig.update_xaxes()  # Update x-axis for better readability\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Bedeutung SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute values of the coefficients as feature importance\n",
    "feature_importance = abs(svm_model.coef_).flatten()\n",
    "\n",
    "# Create DataFrame for Plotly visualization\n",
    "df_plot = pd.DataFrame({\"Feature\": X.columns.tolist(), \"Wichtigkeit\": feature_importance})\n",
    "\n",
    "# Create an interactive bar plot with Plotly\n",
    "fig = px.bar(df_plot, x=\"Feature\", y=\"Wichtigkeit\", title=\"Feature Importance from SVM\", labels={\"Feature\": \"Feature\", \"Wichtigkeit\": \"Feature Importance\"})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature-Engineering\n",
    "\n",
    "Für das Feature Engineering wurden zwei Klassifikationsverfahren ausgewählt. Einmal wurde k-Nearest-Neighbor mit Manhattan Metrik genutzt und zusätzlich klassische Entscheidungsbäume. Diese beiden Klassifikationsverfahren wurden ausgewählt, das k-Nearest-Neighbor mit Manhattan Metrik beim testen die höchste und klassische Entscheidungsbäume die schlechteste Genauigkeit hatten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Generieren der PCA-Hauptkomponenten Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of principal components to keep (can be adjusted)\n",
    "pca_components = 2\n",
    "\n",
    "# Perform PCA transformation with the specified number of components\n",
    "pca = PCA(n_components=pca_components)\n",
    "X_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Convert the PCA results into a DataFrame\n",
    "df_pca = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(pca_components)])\n",
    "\n",
    "# Add the target variable \"KHK\" to the PCA DataFrame\n",
    "df_pca['KHK'] = data['KHK'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(df_pca.drop(columns=[\"KHK\"]), df_pca[\"KHK\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Testen des Feature-Engineering auf k-Nearest-Neighbor mit Manhattan Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modellgenauigkeit: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79        77\n",
      "           1       0.93      0.70      0.80       107\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.81      0.81      0.79       184\n",
      "weighted avg       0.83      0.79      0.79       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create k-NN model with k=10 for PCA features using Manhattan distance\n",
    "knn_model_pca = KNeighborsClassifier(n_neighbors=10, metric='manhattan')\n",
    "\n",
    "# Train the model on PCA-transformed features\n",
    "knn_model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn_pca = knn_model_pca.predict(X_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn_pca = accuracy_score(y_test, y_pred_knn_pca)\n",
    "classification_rep_knn_pca = classification_report(y_test, y_pred_knn_pca)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Model accuracy: {accuracy_knn_pca:.2f}\")\n",
    "print(classification_rep_knn_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Testen des Feature-Engineering auf einem klassischen Entscheidungsbaum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modellgenauigkeit: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66        77\n",
      "           1       0.77      0.68      0.72       107\n",
      "\n",
      "    accuracy                           0.70       184\n",
      "   macro avg       0.69      0.70      0.69       184\n",
      "weighted avg       0.71      0.70      0.70       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree model for PCA features\n",
    "clf_tree_pca = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on PCA-transformed features\n",
    "clf_tree_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_tree_pca = clf_tree_pca.predict(X_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_tree_pca = accuracy_score(y_test, y_pred_tree_pca)\n",
    "classification_rep_tree_pca = classification_report(y_test, y_pred_tree_pca)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Model accuracy: {accuracy_tree_pca:.2f}\")\n",
    "print(classification_rep_tree_pca)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
