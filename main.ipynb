{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendung von maschinellem Lernen auf den KHK_Klassifikation.csv Datensatz\n",
    "\n",
    "## Praktische Demonstration f√ºr verschiedene machine Learning Modelle\n",
    "\n",
    "### Tim Bleicher, Linus Pfeifer\n",
    "\n",
    "Dieses Jupyter Notebook demonstriert die Anwendung von verschiedenen Machine Learning Modellen auf den KHK_Klassifikation.csv Datensatz. \n",
    "\n",
    "# Inhaltsverzeichnis\n",
    "\n",
    "## 1. Einbindung der Daten\n",
    "- **1.1 Explorative Analyse der Daten**\n",
    "\n",
    "## 2. PCA-Dimensionsreduzierung zur Visualisierung und Analyse der Daten\n",
    "- **Funktionsweise von PCA**\n",
    "- **L√§sst sich aus den PCA-Daten eine potentielle gute Separierbarkeit der Klassen ablesen?**\n",
    "\n",
    "## 3. Anwendung verschiedener Klassifikationsverfahren\n",
    "- **Definition und Datenvorbereitung**\n",
    "- **3.1 Logistische Regression**\n",
    "  - 3.1.1 Modell definieren und trainieren\n",
    "  - 3.1.2 Modell testen\n",
    "- **3.2 Entscheidungsb√§ume**\n",
    "  - 3.2.1 Klassische Entscheidungsb√§ume\n",
    "  - 3.2.2 Bagging in Form von Random Forest\n",
    "  - 3.2.3 Boosting in Form von AdaBoost\n",
    "  - 3.2.4 Stacking\n",
    "- **3.3 k-Nearest-Neighbor**\n",
    "  - 3.3.1 k-Nearest-Neighbor mit euklidischer Metrik\n",
    "  - 3.3.2 k-Nearest-Neighbor mit Manhattan Metrik\n",
    "  - 3.3.3 k-Nearest-Neighbor mit Minkowski Metrik (p = 3)\n",
    "- **3.4 Support Vector Machine**\n",
    "- **3.5 Neuronales Netz**\n",
    "\n",
    "## 4. Bedeutung der einzelnen Features\n",
    "- **4.1 Feature-Bedeutung von PCA**\n",
    "- **4.2 Feature-Bedeutung f√ºr Random Forest**\n",
    "- **4.3 Feature-Bedeutung f√ºr SVM**\n",
    "\n",
    "## 5. Feature-Engineering\n",
    "- **5.1 Generieren der PCA-Hauptkomponenten-Daten**\n",
    "- **5.2 Testen des Feature-Engineering auf k-Nearest-Neighbor mit Manhattan Metrik**\n",
    "- **5.3 Testen des Feature-Engineering auf einem klassischen Entscheidungsbaum**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einbindung der Daten\n",
    "\n",
    "Zu beginn des Projekts werden die Daten zun√§chst geladen um diese im anschluss analysieren und nutzen zu k√∂nnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('KHK_Klassifikation.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Explorative Analyse der Daten \n",
    "\n",
    "Die explorative Datenanalyse (EDA) ist ein Ansatz zur Untersuchung von Datens√§tzen, bei dem zun√§chst deren Hauptmerkmale visuell und statistisch beschrieben werden ‚Äì oft noch ohne eine konkrete Hypothese. Ziel ist es, ein erstes Verst√§ndnis f√ºr Struktur, Muster, Ausrei√üer, Verteilungen und potenzielle Zusammenh√§nge in den Daten zu bekommen (vgl. https://www.ibm.com/think/topics/exploratory-data-analysis).\n",
    "\n",
    "### üìÑ Beschreibung der Attribute im Datensatz\n",
    "\n",
    "| Attribut      | Beschreibung |\n",
    "|---------------|-------------|\n",
    "| **Alter** | Alter der Patientin oder des Patienten in Jahren. |\n",
    "| **Geschlecht** | Geschlecht der Person: <br>`M` steht f√ºr m√§nnlich, `F` f√ºr weiblich. |\n",
    "| **Blutdruck** | Systolischer Blutdruck in mmHg (Millimeter Quecksilbers√§ule), gemessen im Ruhezustand. Werte ab 140 gelten in der Regel als erh√∂hter Blutdruck. (vgl. https://www.visomat.de/blutdruck-normalwerte/)|\n",
    "| **Chol** | Gesamtcholesterin im Blut in mg/dL (Milligramm pro Deziliter). Erh√∂hte Werte (>190‚ÄØmg/dL) k√∂nnen ein Risiko f√ºr Herz-Kreislauf-Erkrankungen darstellen. (vgl. https://www.cholesterinspiegel.de/auffaellige-cholesterinwerte/) |\n",
    "| **Blutzucker** | N√ºchtern-Blutzuckerwert: <br>`0` = Normaler Blutzucker <br>`1` = Erh√∂hter Blutzucker (m√∂glicher Hinweis auf Diabetes oder Pr√§diabetes). |\n",
    "| **EKG** | Ergebnis des Ruhe-EKGs. M√∂gliche Kategorien: <br>- `Normal` = unauff√§lliger Befund <br>- `ST` = ST-Streckensenkung (Hinweis auf BelastungsischaÃàmie) <br>- `LVH` = Linksventrikul√§re Hypertrophie (Herzmuskelvergr√∂√üerung). |\n",
    "| **HFmax** | Maximale Herzfrequenz (in Schl√§gen pro Minute), die w√§hrend eines Belastungstests erreicht wurde. Sehr grobe Faustregel: HFmax = 220 - Lebensalter (vgl. https://www.germanjournalsportsmedicine.com/archive/archive-2010/heft-12/die-maximale-herzfrequenz/) |\n",
    "| **AP** | Angina Pectoris bei Belastung: <br>`N` = Keine Symptome <br>`Y` = Auftreten von Angina Pectoris (Brustschmerzen unter Belastung), m√∂glicher Hinweis auf Durchblutungsst√∂rungen des Herzens. |\n",
    "| **RZ** | R√ºckgang (bzw. Ver√§nderung) der ST-Strecke w√§hrend eines Belastungs-EKGs in **mm**. <br> Positive Werte deuten auf eine **ST-Streckensenkung** hin, was auf eine m√∂gliche **Isch√§mie des Herzmuskels** (z.‚ÄØB. bei KHK) hindeuten kann. <br> Negative Werte k√∂nnen als **ST-Streckenhebung** interpretiert werden ‚Äì diese k√∂nnen je nach klinischem Zusammenhang normal, unspezifisch oder auch pathologisch sein (z.‚ÄØB. bei Infarkten oder Perikarditis). <br> In der Regel gilt: Je gr√∂√üer der **absolute Betrag**, desto auff√§lliger der Befund. |\n",
    "| **KHK** | **Zielvariable** ‚Äì Diagnose einer koronaren Herzkrankheit: <br>`0` = Keine KHK <br>`1` = KHK nachgewiesen (positives Ergebnis). |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erster Blick auf die Daten:**  \n",
    "Zuerst wird eine Kopie des Datensatzes erstellt und ein erster Blick auf die obersten Zeilen geworfen.\n",
    "Dies dient dazu einen ersten groben √úberblick √ºber die Daten zu bekommen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of the original dataset\n",
    "df = data.copy()\n",
    "\n",
    "# Display the first few rows\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Allgemeine Informationen:**  \n",
    "Mit `df.info()` erh√§lt man einen √úberblick √ºber die Spalten, Datentypen und Anzahl fehlender Werte. Das ist wichtig, um zu verstehen, welche Features numerisch oder kategorisch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General information about the dataset\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistische Kennzahlen:**  \n",
    "Diese √úbersicht zeigt zentrale Lage- und Streuungsma√üe (z.‚ÄØB. Mittelwert, Standardabweichung) f√ºr alle numerischen Spalten. Das hilft, Ausrei√üer oder ungew√∂hnliche Verteilungen fr√ºhzeitig zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical overview of numerical features\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kategoriale Merkmale analysieren:**  \n",
    "Nun wird die H√§ufigkeit der Werte in allen kategorialen Spalten angesehen. So erkennt man dominante Klassen und m√∂gliche Ungleichgewichte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of values for categorical features\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"\\nValue distribution for '{col}':\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fehlende Werte pr√ºfen:**  \n",
    "Hier wird analysiert, in welchen Spalten Daten fehlen. Dies ist entscheidend f√ºr die sp√§tere Datenbereinigung oder Modellierung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doppelte Eintr√§ge identifizieren:**  \n",
    "Es wird gepr√ºft, ob es doppelte Zeilen gibt ‚Äì diese sollten bei Bedarf entfernt werden, um Verzerrungen zu vermeiden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zielvariable analysieren:**  \n",
    "Ein schneller Blick auf die Verteilung der Zielgr√∂√üe (KHK: koronare Herzkrankheit). So sieht man z.‚ÄØB., ob die Klassen unausgeglichen sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target variable (CHD)\n",
    "print(\"\\nDistribution of the target variable 'CHD':\")\n",
    "print(df[\"KHK\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplots zur √úbersicht:**  \n",
    "Boxplots geben einen schnellen √úberblick √ºber die Verteilung numerischer Merkmale inkl. Ausrei√üer. Dies ist besonders hilfreich zum Erkennen von Extremwerten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_cols_filtered = [\n",
    "    col for col in numerical_cols if df[col].nunique() > 2]\n",
    "\n",
    "for col in numerical_cols_filtered:\n",
    "    fig = px.box(df, y=col, points=\"all\",\n",
    "                 title=f\"Boxplot: {col}\", template=\"plotly_white\")\n",
    "    fig.update_layout(yaxis_title=col)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogramme zur Dichteverteilung:**  \n",
    "Diese Plots zeigen, wie sich die Werte in den numerischen Spalten verteilen. Zus√§tzlich ist oben ein Boxplot integriert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols_filtered:\n",
    "    fig = px.histogram(df, x=col, nbins=20, marginal=\"box\",\n",
    "                       title=f\"Histogramm: {col}\", template=\"plotly_white\", color_discrete_sequence=[\"steelblue\"])\n",
    "    fig.update_layout(xaxis_title=col, yaxis_title=\"H√§ufigkeit\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplots nach KHK-Klassen:**  \n",
    "Hier wird analysiert, ob sich bestimmte numerische Merkmale in Abh√§ngigkeit von der Zielvariable signifikant unterscheiden. Das kann Hinweise auf relevante Pr√§diktoren liefern.\n",
    "\n",
    "Wichtig zu erw√§hnen ist, dass viele Chol Werte 0 sind, was auf fehlende Daten hinweist. Daher wurden diese Werte herausgefiltert, um die Statistiken nicht zu verf√§lschen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols_khk = [\n",
    "    col for col in numerical_cols\n",
    "    if df[col].nunique() > 2 and col != \"KHK\" and col != \"Blutzucker\"\n",
    "]\n",
    "\n",
    "for col in numerical_cols_khk:\n",
    "    df_plot = df.copy()\n",
    "\n",
    "    # For the Chol column: exclude values with 0\n",
    "    if col == \"Chol\":\n",
    "        df_plot = df_plot[df_plot[\"Chol\"] != 0]\n",
    "\n",
    "    fig = px.box(df_plot, x=\"KHK\", y=col, color=\"KHK\",\n",
    "                 title=f\"{col} by CHD class\", template=\"plotly_white\", points=\"all\")\n",
    "    fig.update_layout(xaxis_title=\"CHD (0 = No, 1 = Yes)\", yaxis_title=col)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA-Dimensionsreduzierung zur Visualisierung und Analyse der Daten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionsweise von PCA\n",
    "Die Hauptkomponentenanalyse (PCA) dient der Dimensionsreduktion eines Datensatzes. Dies erm√∂glicht beispielsweise verschiedene Analyse des gesamten Datensatzes (mit mehr als 3 Dimensionen), wobei die Ergebnisse durch die Dimensionsreduktion weiterhin visualisiert werden k√∂nnen.\n",
    "Das Verfahren der PCA l√§uft nach folgendem Schema ab:\n",
    "\n",
    "1. Berechnung des Mittelwerts und Zentrierung der Daten\n",
    "2. Berechnung der Kovarianzmatrix\n",
    "3. Berechnung der Eigenwerte und Eigenvektoren\n",
    "4. Transformation der Daten\n",
    "\n",
    "Damit die PCA korrekt funktioniert, muss zun√§chst von jeder Dimension der Mittelwert subtrahiert werden. Dieser Mittelwert entspricht dem Durchschnittswert jeder Dimension. Beispielsweise wird von allen $x$-Werten der Mittelwert $\\overline{x}$ subtrahiert. Entsprechendes gilt f√ºr die anderen Dimensionen der Daten. Dadurch entsteht ein Datensatz mit einem Mittelwert von null.\n",
    "\n",
    "Im n√§chsten Schritt wird die Kovarianzmatrix berechnet, welche die wechselseitigen Zusammenh√§nge zwischen den Merkmalen quantifiziert. Falls zwei Merkmale stark korrelieren, k√∂nnen diese in einer neuen Achse kombiniert werden.\n",
    "\n",
    "Anschlie√üend werden die Eigenwerte und Eigenvektoren der Kovarianzmatrix bestimmt. Die Eigenvektoren definieren die Richtungen der Hauptkomponenten, w√§hrend die zugeh√∂rigen Eigenwerte die Bedeutung bzw. die Varianz der jeweiligen Eigenvektoren widerspiegeln.\n",
    "\n",
    "Es folgt die eigentliche Dimensionsreduktion, indem nur diejenigen Eigenvektoren mit den gr√∂√üten Eigenwerten ausgew√§hlt werden. Diese Eigenvektoren entsprechen den neuen Hauptachsen des Datensatzes.\n",
    "\n",
    "Schlie√ülich werden die Daten transformiert, indem die urspr√ºngliche Datenmatrix mit der Matrix der Eigenvektoren multipliziert wird. In dieser Matrix repr√§sentiert jede Spalte einen Eigenvektor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['Geschlecht', 'EKG', 'AP']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    # Encode categorical columns\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target variable \"KHK\" before scaling\n",
    "data_without_target = data.drop(columns=[\"KHK\"], errors=\"ignore\")\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_without_target)\n",
    "\n",
    "# PCA transformation with two principal components\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Convert the PCA results into a DataFrame\n",
    "df_pca = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Interactive visualization\n",
    "fig = px.scatter(df_pca, x='PC1', y='PC2', title='PCA Visualization of the Data', opacity=0.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[\"KHK\"]\n",
    "df_pca['KHK'] = target\n",
    "\n",
    "df_pca['KHK'] = df_pca['KHK'].astype('category')\n",
    "\n",
    "# Interactive visualization with colors based on KHK (0 = blue, 1 = red)\n",
    "fig = px.scatter(\n",
    "    df_pca,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='KHK',\n",
    "    color_discrete_map={0: 'blue', 1: 'red'},  # Discrete color mapping\n",
    "    title='PCA visualization colored by KHK class',\n",
    "    opacity=0.5\n",
    ")\n",
    "\n",
    "# Adjust marker size and legend settings\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.update_layout(\n",
    "    legend_title_text='KHK',  # Clearly label the legend\n",
    "    showlegend=True           # Ensure the legend is displayed\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L√§sst sich aus den PCA-Daten eine potentielle gute Separierbarkeit der Klassen ablesen?\n",
    "\n",
    "Es sind zwar einzelne \"Flecken\" zu sehen, die etwas konzentriertere Mengen an Punkten darstellen, jedoch ist es schwierig m√∂glich hieraus verschiedene Klassen abzuleiten.\n",
    "Dies liegt vor allem an der Reduktion der Vielzahl an Attributen auf nur 2 Hauptachsen, wobei dann doch zu viele Informationen bei der Darstellung verloren gehen.\n",
    "Sind die Zusammenh√§nge von Attributen nicht-linear (wovon man in diesem Datensatz erstmal ausgehen kann), so gehen wichtige Informationen bei der PCA verloren, da die Abbildung auf den niedrigdimensionalen Raum lediglich linear ist (vgl. Skript ML_10_Dimensionsreduktion S.16-17).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anwendung verschiedener vorgestellter Klassifikationsverfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition und Datenvorbereitung\n",
    "\n",
    "Zun√§chst werden die kategorialen und numerischen Merkmale des Datensatzes definiert. Anschlie√üend erfolgt die Vorbereitung der Daten f√ºr ein Machine-Learning-Modell. Dazu geh√∂ren die Auswahl und Umordnung der Merkmale, die Umwandlung kategorialer Variablen mittels Label-Encoding (vgl. https://kantschants.com/complete-guide-to-encoding-categorical-features), die Standardisierung der numerischen Variablen sowie die Aufteilung in Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical columns\n",
    "categorical_features = [\"Geschlecht\", \"EKG\", \"AP\"]\n",
    "numerical_features = [\"Alter\", \"Blutdruck\", \"Chol\", \"Blutzucker\", \"HFmax\", \"RZ\"]\n",
    "\n",
    "# Select target variable and features\n",
    "X = data[categorical_features + numerical_features].copy()\n",
    "y = data[\"KHK\"]\n",
    "\n",
    "# Reorder features to match the desired order\n",
    "desired_order = [\"Alter\", \"Geschlecht\", \"Blutdruck\", \"Chol\", \"Blutzucker\", \"EKG\", \"HFmax\", \"AP\", \"RZ\"]\n",
    "X = X[desired_order]\n",
    "\n",
    "# Apply Label Encoding to categorical features\n",
    "label_encoders = {}  # Store LabelEncoder objects\n",
    "for col in categorical_features:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistische Regression\n",
    "Logistische Regression ist ein statistisches Modell, das den nat√ºrlichen Logarithmus der Chancen eines Ereignisses als lineare Kombination einer oder mehrerer unabh√§ngiger Variablen modelliert.\n",
    "In der Regressionsanalyse sch√§tzt die logistische Regression die Parameter dieses Modells, typischerweise in Szenarien mit einer bin√§ren Zielvariablen (z.‚ÄØB. 0 oder 1) (vgl. https://en.wikipedia.org/wiki/Logistic_regression).\n",
    "\n",
    "Logistische Regression passt gut zu dem Datensatz, da KHK bin√§r ist, der Datensatz gemischte Merkmale enth√§lt und das Modell wahrscheinlichkeiten f√ºr KHK einfach und interpretierbar berechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Modell definieren und trainieren\n",
    "\n",
    "Das beschriebene logistische Regressionsmodell wird erstellt und mit den Trainingsdaten trainiert, um KHK als bin√§re Zielvariable vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression for binary classification\n",
    "\n",
    "# Create pipeline with preprocessing and logistic regression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Modell testen\n",
    "\n",
    "Das trainierte Modell wird auf den Testdaten angewendet. Die Auswertung erfolgt anhand der **Genauigkeit (Accuracy)** und eines **Classification Reports**, der die wichtigsten Metriken zur Bewertung der Vorhersagequalit√§t enth√§lt:\n",
    "\n",
    "| **Metrik**     | **Beschreibung**                                                                 |\n",
    "|----------------|-----------------------------------------------------------------------------------|\n",
    "| **Accuracy**   | Anteil korrekt klassifizierter Beispiele an allen Beispielen                     |\n",
    "| **Precision**  | Anteil korrekt positiver Vorhersagen an allen als positiv vorhergesagten F√§llen (vgl. https://www.v7labs.com/blog/precision-vs-recall-guide)  |\n",
    "| **Recall**     | Anteil korrekt erkannter positiver F√§lle an allen tats√§chlichen positiven F√§llen (vgl. https://www.v7labs.com/blog/precision-vs-recall-guide) |\n",
    "| **F1-Score**   | Harmonisches Mittel aus Precision und Recall (balanciert beide Metriken) (vgl. https://www.v7labs.com/blog/f1-score-guide)       |\n",
    "\n",
    "Diese Metriken geben gemeinsam ein gutes Bild dar√ºber, wie zuverl√§ssig das Modell bei der KHK-Klassifikation arbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_log_reg = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "classification_rep = classification_report(y_test, y_pred_log_reg)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die logistische Regression erzielt eine Genauigkeit von 76‚ÄØ% und zeigt insgesamt eine ausgewogene Leistung.\n",
    "Besonders bei der Erkennung von KHK-F√§llen (Klasse 1) schneidet das Modell gut ab, mit einer Pr√§zision von 82‚ÄØ% und einem Recall von 76‚ÄØ%.\n",
    "Die Klasse 0 (keine KHK) wird mit etwas geringerer Pr√§zision (69‚ÄØ%) erkannt, aber mit solider Sensitivit√§t (77‚ÄØ%).\n",
    "\n",
    "Insgesamt liefert das Modell stabile und gut ausbalancierte Vorhersagen und eignet sich als verl√§sslicher Basisansatz f√ºr die Klassifikation von KHK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Entscheidungsb√§ume\n",
    "\n",
    "Ein Entscheidungsbaum ist ein geordneter, gerichteter Baum, der Entscheidungsregeln in einer hierarchischen Struktur darstellt\n",
    "Jeder Knoten repr√§sentiert eine Bedingung oder Entscheidungsregel basierend auf einem Merkmal des Datensatzes (vgl. https://de.wikipedia.org/wiki/Entscheidungsbaum).\n",
    "Die Blattknoten am Ende des Baums geben die Vorhersage oder Klassenzugeh√∂rigkeit aus (in unserem Fall KHK = 0 oder 1).\n",
    "Die Struktur erm√∂glicht es, Daten schrittweise entlang dieser Bedingungen aufzuteilen, um zu einer fundierten Entscheidung zu gelangen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Klassische Entscheidungsb√§ume\n",
    "\n",
    "Der klassische Entscheidungsbaum funktioniert wie in [3.2](#32-entscheidungsb√§ume) beschrieben. Es werden keine Ensemble-Methoden verwendet, sondern ein einzelner Baum erstellt, der rekursiv durch Splits an Knotenpunkten aufgebaut wird.\n",
    "\n",
    "Auch hier wird die Klassifikation wieder an den schon beschriebenen Metriken gemessen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree Classifier\n",
    "clf_tree = DecisionTreeClassifier(random_state=42)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_tree = clf_tree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "classification_rep_tree = classification_report(y_test, y_pred_tree)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_tree:.2f}\")\n",
    "print(classification_rep_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der klassische Entscheidungsbaum erreicht eine Genauigkeit von 64‚ÄØ% und bleibt damit deutlich hinter der logistischen Regression zur√ºck.\n",
    "W√§hrend KHK-F√§lle (Klasse 1) mit einer Pr√§zision von 70‚ÄØ% noch relativ gut erkannt werden, zeigt das Modell bei der Klasse 0 (keine KHK) Schw√§chen, vor allem bei der Pr√§zision mit nur 56‚ÄØ%.\n",
    "\n",
    "F√ºr den vorliegenden Datensatz liefert der klassische Entscheidungsbaum somit nur begrenzte Vorhersagequalit√§t und generalisiert schlechter als das lineare Modell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Bagging in Form von Random Forest\n",
    "Random Forest ist ein Modell, das viele Entscheidungsb√§ume kombiniert. Jeder Baum wird auf zuf√§lligen Daten und Merkmalen trainiert.\n",
    "Die Vorhersagen der B√§ume werden am Ende zusammengefasst (beispielsweise per Mehrheitsentscheid). Dadurch wird das Modell stabiler und genauer als ein einzelner Baum (vgl. https://www.ibm.com/de-de/think/topics/random-forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_random_forest = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "classification_rep = classification_report(y_test, y_pred_random_forest)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_random_forest:.2f}\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Random Forest erzielt eine Genauigkeit von 73‚ÄØ% und liegt damit leicht unterhalb der logistischen Regression, aber deutlich √ºber dem einfachen Entscheidungsbaum.\n",
    "Die Klasse 1 (KHK) wird mit einer Pr√§zision von 78‚ÄØ% und einem Recall von 75‚ÄØ% zuverl√§ssig erkannt. Auch Klasse 0 (keine KHK) erreicht solide Werte mit 67‚ÄØ% Pr√§zision und 71‚ÄØ% Recall.\n",
    "Insgesamt zeigt das Modell eine ausgewogene Leistung mit guter Generalisierungsf√§higkeit.\n",
    "\n",
    "Daddurch, dass viele Entscheidungsb√§ume kombiniert werden, kann Random Forest wohl komplexere Zusammenh√§nge gut erfassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Boosting in Form von AdaBoost\n",
    "\n",
    "Adaptive Boosting ist einer der bekanntesten und breitesten Boosting Algorithmen.\n",
    "Mehrere schwache Modelle werden nacheinander trainiert, wobei jedes neue Modell gezielt die Fehler der vorherigen korrigiert, indem falsch klassifizierte Daten st√§rker gewichtet werden. Die endg√ºltige Vorhersage entsteht durch ein gewichtetes Mehrheitsvotum(vgl. Skript ML_08_Modelle-V S.26-34)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Train AdaBoost model with specified parameters\n",
    "adaboost_model = AdaBoostClassifier(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ada = adaboost_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_ada)  # Note: variable name might be misleading\n",
    "classification_rep = classification_report(y_test, y_pred_ada)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_random_forest:.2f}\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das AdaBoost-Modell erreicht eine Genauigkeit von 77‚ÄØ% und liefert damit das (in der chronologischen Reihenfolge des Notebooks) bislang beste Ergebnis unter den getesteten Verfahren.\n",
    "Die Klasse 0 (keine KHK) wird mit einer Pr√§zision von 70‚ÄØ% und einem Recall von 78‚ÄØ% solide erkannt, w√§hrend die Klasse 1 (KHK) mit 83‚ÄØ% Pr√§zision und 76‚ÄØ% Recall besonders zuverl√§ssig vorhergesagt wird.\n",
    "\n",
    "Durch das schrittweise Lernen aus Fehlern fr√ºherer Modelle gelingt AdaBoost eine gut ausbalancierte Klassifikation, die sowohl Pr√§zision als auch Sensitivit√§t ber√ºcksichtigt. Im Vergleich zur logistischen Regression und zum Random Forest schneidet AdaBoost leicht besser ab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Stacking\n",
    "\n",
    "Stacking kombiniert verschiedene Modelle, die jeweils unterschiedliche Bereiche der Merkmalsverteilung gut abdecken, und nutzt deren Vorhersagen gemeinsam, um die Gesamtvorhersage zu verbessern(vgl. Skript ML_08_Modelle-V S.40-42).\n",
    "Es ist besondern gut anzuwenden, wenn die Einzelmodelle ausreichend verschieden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base models: KNN, SVM, and Logistic Regression\n",
    "base_estimators = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),  # KNN with 5 neighbors\n",
    "    ('svc', SVC(kernel='linear', random_state=42)),  # SVM with a linear kernel\n",
    "    ('logreg', LogisticRegression(random_state=42))  # Logistic Regression\n",
    "]\n",
    "\n",
    "# Final model (meta-model)\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# Create StackingClassifier with base models and final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_estimators, final_estimator=final_estimator)\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_stack = accuracy_score(y_test, y_pred_stack)\n",
    "classification_rep = classification_report(y_test, y_pred_stack)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_stack:.2f}\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Stacking-Modell erreicht eine Genauigkeit von 76‚ÄØ% und liegt damit auf dem Niveau der logistischen Regression und knapp unter AdaBoost. Es kombiniert KNN, SVM und logistische Regression als Basis-Modelle und nutzt erneut eine logistische Regression als Meta-Modell, das aus den Vorhersagen der Basismodelle lernt.\n",
    "Die Klasse 0 (keine KHK) wird mit 69‚ÄØ% Pr√§zision und 77‚ÄØ% Recall erkannt, w√§hrend Klasse 1 (KHK) mit 82‚ÄØ% Pr√§zision und 75‚ÄØ% Recall klassifiziert wird.\n",
    "\n",
    "Das Modell ist insgesamt ausgewogen, profitiert wohl von der Vielfalt der Basismodelle und zeigt, dass sich durch geschickte Kombination unterschiedlicher Ans√§tze eine solide Vorhersagequalit√§t erzielen l√§sst.\n",
    "Trotzdem ist das Modell minimal schlechter als das verhorige AdaBoost Modell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 k-Nearest-Neighbor\n",
    "KNN ist ein einfacher Algorithmus, der neue Datenpunkte anhand der k √§hnlichsten bekannten Punkte einordnet.\n",
    "Er speichert nur die Trainingsdaten und trifft Entscheidungen bei der Vorhersage, basierend auf dem Abstand zu den n√§chsten Nachbarn (vgl. https://www.ibm.com/de-de/think/topics/knn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 k-Nearest-Neighbor mit euklidischer Metrik\n",
    "\n",
    "Es wird der direkcte Abstand zwischen zwei Punkten im Merkmalsraum gemessen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 and Euclidean distance metric\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10, metric='euclidean')\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "classification_rep_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_knn:.2f}\")\n",
    "print(classification_rep_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-NN-Modell mit euklidischer Distanz liefert mit 78‚ÄØ% Genauigkeit das momentan beste Ergebnis (chronologisch anhand des Notebooks). Besonders auff√§llig ist die starke Leistung bei Klasse 0 (keine KHK): Mit einem Recall von 87‚ÄØ% erkennt das Modell sehr zuverl√§ssig gesunde F√§lle, auch wenn die Pr√§zision bei 68‚ÄØ% liegt. F√ºr Klasse 1 (KHK) ist die Pr√§zision mit 88‚ÄØ% sogar noch h√∂her, aber der Recall etwas niedriger bei 71‚ÄØ%.\n",
    "\n",
    "Insgesamt zeigt sich ein leichtes Ungleichgewicht: Das Modell erkennt gesunde Patienten sehr sicher, neigt aber dazu, einige KHK-F√§lle zu √ºbersehen.\n",
    "Dennoch ist die F1-Balance sehr gut und das Modell profitiert offenbar davon, dass k-NN bei gut strukturierten Daten (StandardScaler()) effektiv trennen kann (vgl. https://medium.com/@RobuRishabh/knn-k-nearest-neighbour-5ae18ae8e274)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 k-Nearest-Neighbor mit manhattan Metrik\n",
    "\n",
    "Es wird der Abstand zwischen zwei Punkten als Summe der absoluten Differenzen der Merkmalswerte berechnet (Analogie zu rechteckigen Stra√üennetzen).\n",
    "Dies erm√∂glicht h√∂here Robustheit gegen Au√ürei√üer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 and Manhattan distance metric\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10, metric='manhattan')\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "classification_rep_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_knn:.2f}\")\n",
    "print(classification_rep_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-NN-Modell mit Manhattan-Distanz erzielt mit 79‚ÄØ% Genauigkeit die bisher beste Gesamtleistung aller getesteten Modelle.\n",
    "\n",
    "F√ºr Klasse 0 (keine KHK) erreicht es einen sehr hohen Recall von 87‚ÄØ%, was bedeutet, dass gesunde F√§lle fast vollst√§ndig erkannt werden. Die Pr√§zision liegt bei akzeptablen 70%.\n",
    "Klasse 1 (KHK) wird mit 89‚ÄØ% Pr√§zision und 73‚ÄØ% Recall sehr zuverl√§ssig vorhergesagt.\n",
    "\n",
    "Die Manhattan-Metrik scheint in diesem Fall besonders gut zu den strukturellen Eigenschaften des Datensatzes zu passen. Sie reagiert robuster auf einzelne Ausrei√üer in den Merkmalen und scheint damit eine bessere Trennung zwischen den Klassen zu erm√∂glichen als die euklidische Distanz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 k-Nearest-Neighbor mit Minkowski Metrik und p = 3\n",
    "\n",
    "Die Minkowski Metrik kann √ºber den Parameter p verschiedene Distanzen annehmen.\n",
    "p = 3 deutet den √úbergang zwischen euklidischen und Tschebyscheff-Abst√§nden an (vgl. https://www.datacamp.com/de/tutorial/minkowski-distance).\n",
    "Hierbei werden Abst√§nde bei Gr√∂√üeren Unterschieden st√§rker betont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 and Minkowski distance metric (p=3)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10, metric='minkowski', p=3)\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "classification_rep_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_knn:.2f}\")\n",
    "print(classification_rep_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-NN-Modell mit Minkowski-Distanz erreicht eine Genauigkeit von 77‚ÄØ% und liegt damit im oberen Leistungsbereich der bisher getesteten Verfahren.\n",
    "F√ºr Klasse 0 (keine KHK) ist der Recall mit 86‚ÄØ% besonders hoch, womit das Modell gesunde F√§lle zuverl√§ssig erkennt, obwohl die Pr√§zision mit 67‚ÄØ% etwas niedriger ausf√§llt.\n",
    "Klasse 1 (KHK) wird mit 87‚ÄØ% Pr√§zision und 70‚ÄØ% Recall ebenfalls solide vorhergesagt.\n",
    "\n",
    "Wie schon in der Beschreibung von [3.3.4](#334-k-nearest-neighbor-mit-minkowski-metrik-und-p-3) angesprochen, f√ºhrt p = 3 zu einer Gewichtung, die gr√∂√üere Abst√§nde st√§rker ber√ºcksichtigt als bei euklidischer oder Manhattan-Metrik. Dadurch kann das Modell empfindlicher auf auff√§llige Merkmalsunterschiede reagieren, welche jedoch auch nicht immer berechtigt sind, wenn man die Genauigkeit f√ºr p = 1 und p = 2 vergleicht.\n",
    "\n",
    "Insgesamt bietet dieses Modell eine ausgewogene Performance, √§hnlich wie die Varianten mit euklidischer oder Manhattan-Metrik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Support Vector Machine\n",
    "\n",
    "SVM ist ein supervised Klassifikationsverfahren, das eine Hyperebene mit dem gr√∂√ütm√∂glichen Abstand zwischen zwei Klassen findet.\n",
    "Wichtig sind dabei die Support-Vektoren, die die Trennung bestimmen.\n",
    "SVMs sind leistungsstark, aber oft schwer interpretierbar und rechenintensiv. Mit Soft-Margin k√∂nnen auch nicht perfekt trennbare Daten verarbeitet werden (vgl. Skript ML_07_Modelle-IV S.41-49)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM model with a linear kernel\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model accuracy: {accuracy_svm:.2f}\")\n",
    "print(classification_rep_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das SVM-Modell erreicht eine Genauigkeit von 77‚ÄØ% und liefert damit ein gutes Ergebnis, vergleichbar mit AdaBoost und den besten k-NN-Varianten.\n",
    "Die Klasse 0 (keine KHK) wird mit 79‚ÄØ% Recall gut erkannt, allerdings liegt die Pr√§zision bei 69‚ÄØ%, was auf einige falsch positive Vorhersagen hinweist.\n",
    "Klasse 1 (KHK) zeigt eine hohe Pr√§zision von 83‚ÄØ% bei solidem Recall von 75‚ÄØ%. Das Modell identifiziert KHK-F√§lle also sehr zuverl√§ssig.\n",
    "\n",
    "Da ein linearer Kernel verwendet wird, zeigt das gute Ergebnis, dass sich die Daten offenbar weitgehend linear trennen lassen, was auch durch die gute Balance von Pr√§zision und Recall unterstrichen wird.\n",
    "Gleichzeitig ist das Modell einfacher und weniger komplex zu trainieren als nichtlineare SVMs (vgl. https://www.ibm.com/think/topics/support-vector-machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Neuronales Netz\n",
    "\n",
    "Ein neuronales Netz besteht aus mehreren Schichten k√ºnstlicher Neuronen, die √ºber gewichtete Verbindungen Informationen weitergeben.\n",
    "Ein Neuron wird aktiviert, wenn sein Output einen Schwellenwert √ºberschreitet. So lernt das Netz, Muster in Daten zu erkennen (vgl. https://www.ibm.com/de-de/topics/neural-networks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer):\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer\n",
    "        Dense(32, activation='relu'),  # Second hidden layer\n",
    "        Dense(16, activation='relu'),  # Third hidden layer\n",
    "        Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,  # Set optimizer\n",
    "                  loss='binary_crossentropy',  # Loss function for binary classification\n",
    "                  metrics=['accuracy'])  # Metrics to track during training\n",
    "\n",
    "    # Display model summary\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using the SGD optimizer\n",
    "sgd_model = create_model(optimizer='sgd')\n",
    "\n",
    "# Train the model\n",
    "history_sgd = sgd_model.fit(X_train, y_train,\n",
    "                            epochs=50,  # Number of epochs for training\n",
    "                            batch_size=32,  # Batch size for training\n",
    "                            validation_split=0.2,  # Split of training data for validation\n",
    "                            verbose=1)  # Display progress during training\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_sgd, test_accuracy_sgd = sgd_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Visualize training history with Plotly\n",
    "\n",
    "# Plot Accuracy\n",
    "fig_accuracy = go.Figure()\n",
    "fig_accuracy.add_trace(go.Scatter(x=list(range(1, 51)), y=history_sgd.history['accuracy'],\n",
    "                                 mode='lines', name='Training Accuracy'))\n",
    "fig_accuracy.add_trace(go.Scatter(x=list(range(1, 51)), y=history_sgd.history['val_accuracy'],\n",
    "                                 mode='lines', name='Validation Accuracy'))\n",
    "\n",
    "fig_accuracy.update_layout(\n",
    "    title='Model Accuracy',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Accuracy'\n",
    ")\n",
    "\n",
    "# Plot Loss\n",
    "fig_loss = go.Figure()\n",
    "fig_loss.add_trace(go.Scatter(x=list(range(1, 51)), y=history_sgd.history['loss'],\n",
    "                             mode='lines', name='Training Loss'))\n",
    "fig_loss.add_trace(go.Scatter(x=list(range(1, 51)), y=history_sgd.history['val_loss'],\n",
    "                             mode='lines', name='Validation Loss'))\n",
    "\n",
    "fig_loss.update_layout(\n",
    "    title='Model Loss',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss'\n",
    ")\n",
    "\n",
    "# Show the figures\n",
    "fig_accuracy.show()\n",
    "fig_loss.show()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "y_pred_classes_sgd = (y_pred_sgd > 0.5).astype(int)  # Convert probabilities to binary classes\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nTest Accuracy: {test_accuracy_sgd:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes_sgd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grafische Analyse**\n",
    "\n",
    "Die beiden dargestellten Graphen zeigen den Verlauf von Genauigkeit (Accuracy) und Verlust (Loss) √ºber 50 Trainings-Epochen. In der oberen Grafik ist zu erkennen, dass sowohl die Trainingsgenauigkeit als auch die Validierungsgenauigkeit kontinuierlich ansteigen und sich gegen Ende des Trainings auf einem hohen Niveau bei ca. 84‚ÄØ% einpendeln. Dabei verlaufen beide Linien sehr nah beieinander, was ein Hinweis darauf ist, dass das Modell nicht overfitted und gut verallgemeinert.\n",
    "\n",
    "In der unteren Grafik zum Loss zeigt sich ein analoges Bild: Sowohl der Trainings- als auch der Validierungsverlust sinken stetig, was auf eine stabile Optimierung des Modells hinweist. Auch hier verlaufen die Linien gleichm√§√üig und ohne pl√∂tzliche Ausschl√§ge, was f√ºr ein ruhiges, zuverl√§ssiges Lernverhalten spricht.\n",
    "\n",
    "**Statistische Analyse**\n",
    "\n",
    "Auf dem Testdatensatz erreicht das neuronale Netz eine Genauigkeit von 76,1‚ÄØ%, was mit den besten klassischen Verfahren wie SVM, AdaBoost oder k-NN vergleichbar ist.\n",
    "Die Klasse 1 (KHK) wird besonders zuverl√§ssig erkannt, mit einer Pr√§zision von 81‚ÄØ% und einem Recall von 78‚ÄØ%. Das bedeutet, dass wenige gesunde Patienten f√§lschlich als krank eingestuft und auch die meisten tats√§chlichen KHK-F√§lle korrekt erkannt werden.\n",
    "\n",
    "Die Klasse 0 (keine KHK) wird mit einer Pr√§zision von 70‚ÄØ% und einem Recall von 74‚ÄØ% etwas schw√§cher, aber dennoch solide erfasst. Die F1-Scores von 72‚ÄØ% (Klasse 0) und 79‚ÄØ% (Klasse 1) deuten auf eine ausgewogene Gesamtleistung hin, ohne starke Verzerrung zugunsten einer Klasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using the Adam optimizer\n",
    "adam_model = create_model(optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "history_adam = adam_model.fit(X_train, y_train,\n",
    "                              epochs=50,  # Number of epochs for training\n",
    "                              batch_size=32,  # Batch size for training\n",
    "                              validation_split=0.2,  # Split of training data for validation\n",
    "                              verbose=1)  # Display progress during training\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy_adam = adam_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Visualize training history with Plotly\n",
    "\n",
    "# Plot Accuracy\n",
    "fig_accuracy_adam = go.Figure()\n",
    "fig_accuracy_adam.add_trace(go.Scatter(x=list(range(1, 51)), y=history_adam.history['accuracy'],\n",
    "                                      mode='lines', name='Training Accuracy'))\n",
    "fig_accuracy_adam.add_trace(go.Scatter(x=list(range(1, 51)), y=history_adam.history['val_accuracy'],\n",
    "                                      mode='lines', name='Validation Accuracy'))\n",
    "\n",
    "fig_accuracy_adam.update_layout(\n",
    "    title='Model Accuracy',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Accuracy'\n",
    ")\n",
    "\n",
    "# Plot Loss\n",
    "fig_loss_adam = go.Figure()\n",
    "fig_loss_adam.add_trace(go.Scatter(x=list(range(1, 51)), y=history_adam.history['loss'],\n",
    "                                  mode='lines', name='Training Loss'))\n",
    "fig_loss_adam.add_trace(go.Scatter(x=list(range(1, 51)), y=history_adam.history['val_loss'],\n",
    "                                  mode='lines', name='Validation Loss'))\n",
    "\n",
    "fig_loss_adam.update_layout(\n",
    "    title='Model Loss',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss'\n",
    ")\n",
    "\n",
    "# Show the figures\n",
    "fig_accuracy_adam.show()\n",
    "fig_loss_adam.show()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_adam = adam_model.predict(X_test)\n",
    "y_pred_classes_adam = (y_pred_adam > 0.5).astype(int)  # Convert probabilities to binary classes\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nTest Accuracy: {test_accuracy_adam:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes_adam))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grafische Analyse**\n",
    "\n",
    "In der oberen Grafik ist der Verlauf der Trainings- und Validierungsgenauigkeit zu sehen. Das Modell erreicht bereits nach wenigen Epochen sehr gute Werte, wobei die Trainingsgenauigkeit weiter kontinuierlich ansteigt, w√§hrend sich die Validierungsgenauigkeit ab etwa Epoche 10 auf einem Plateau bei ca. 84‚ÄØ% einpendelt. Die Kurven beginnen ab dann deutlich auseinanderzulaufen, was ein Hinweis auf Overfitting ist.\n",
    "\n",
    "In der unteren Grafik erkennt man, dass der Trainings-Loss stetig sinkt, der Validierungs-Loss jedoch ab etwa Epoche 10 nicht weiter f√§llt, sondern sp√§ter sogar leicht ansteigt. Auch das deutet darauf hin, dass das Modell beginnt, sich zu stark auf die Trainingsdaten zu spezialisieren und die Generalisierung auf neue Daten nicht mehr im Fokus steht.\n",
    "\n",
    "Ein fr√ºheres Stoppen (Early Stopping )w√§re sinnvoll, um das beginnende Overfitting zu verhindern.\n",
    "\n",
    "**Statistische Analyse**\n",
    "\n",
    "Das Modell erzielt genau wie das vorherige Modell auf den Testdaten eine Genauigkeit von 76,1‚ÄØ%, was ein solides Ergebnis darstellt. Die Leistung ist damit ebenfalls vergleichbar mit anderen starken Verfahren wie SVM oder AdaBoost.\n",
    "Klasse 0 (keine KHK) wird mit 71‚ÄØ% Pr√§zision und Recall erkannt, Klasse 1 (KHK) mit jeweils 79‚ÄØ%. Das Modell erfasst KHK-F√§lle somit zuverl√§ssiger als gesunde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bedeutung der einzelnen Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature-Bedeutung von PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names (excluding the target variable \"KHK\")\n",
    "feature_names = data.columns.tolist()\n",
    "feature_names.remove(\"KHK\")\n",
    "\n",
    "# Compute the importance of features from PCA components\n",
    "feature_importance = np.abs(pca.components_).sum(axis=0)\n",
    "\n",
    "# Create DataFrame for Plotly visualization\n",
    "df_plot = pd.DataFrame({\"Feature\": feature_names, \"Wichtigkeit\": feature_importance})\n",
    "\n",
    "# Create an interactive bar plot with Plotly\n",
    "fig = px.bar(df_plot, x=\"Feature\", y=\"Wichtigkeit\", title=\"Feature Importance from PCA\", labels={\"Feature\": \"Feature\", \"Wichtigkeit\": \"Feature Importance\"})\n",
    "fig.update_xaxes()  # Update x-axis for better readability\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature-Bedeutung f√ºr Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importance from the Random Forest model\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Create DataFrame for Plotly visualization\n",
    "df_plot = pd.DataFrame({\"Feature\": X.columns.tolist(), \"Wichtigkeit\": feature_importance})\n",
    "\n",
    "# Create an interactive bar plot with Plotly\n",
    "fig = px.bar(df_plot, x=\"Feature\", y=\"Wichtigkeit\", title=\"Feature Importance from Random Forest\", labels={\"Feature\": \"Feature\", \"Wichtigkeit\": \"Feature Importance\"})\n",
    "fig.update_xaxes()  # Update x-axis for better readability\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Bedeutung SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute values of the coefficients as feature importance\n",
    "feature_importance = abs(svm_model.coef_).flatten()\n",
    "\n",
    "# Create DataFrame for Plotly visualization\n",
    "df_plot = pd.DataFrame({\"Feature\": X.columns.tolist(), \"Wichtigkeit\": feature_importance})\n",
    "\n",
    "# Create an interactive bar plot with Plotly\n",
    "fig = px.bar(df_plot, x=\"Feature\", y=\"Wichtigkeit\", title=\"Feature Importance from SVM\", labels={\"Feature\": \"Feature\", \"Wichtigkeit\": \"Feature Importance\"})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature-Engineering\n",
    "\n",
    "F√ºr das Feature Engineering wurden zwei Klassifikationsverfahren ausgew√§hlt. Einmal wurde k-Nearest-Neighbor mit Manhattan Metrik genutzt und zus√§tzlich klassische Entscheidungsb√§ume. Diese beiden Klassifikationsverfahren wurden ausgew√§hlt, dass k-Nearest-Neighbor mit Manhattan Metrik beim testen die h√∂chste und klassische Entscheidungsb√§ume die schlechteste Genauigkeit hatten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Generieren der PCA-Hauptkomponenten Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of principal components to keep (can be adjusted)\n",
    "pca_components = 2\n",
    "\n",
    "# Perform PCA transformation with the specified number of components\n",
    "pca = PCA(n_components=pca_components)\n",
    "X_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Convert the PCA results into a DataFrame\n",
    "df_pca = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(pca_components)])\n",
    "\n",
    "# Add the target variable \"KHK\" to the PCA DataFrame\n",
    "df_pca['KHK'] = data['KHK'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(df_pca.drop(columns=[\"KHK\"]), df_pca[\"KHK\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Testen des Feature-Engineering auf k-Nearest-Neighbor mit Manhattan Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 for PCA features using Manhattan distance\n",
    "knn_model_pca = KNeighborsClassifier(n_neighbors=10, metric='manhattan')\n",
    "\n",
    "# Train the model on PCA-transformed features\n",
    "knn_model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn_pca = knn_model_pca.predict(X_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn_pca = accuracy_score(y_test, y_pred_knn_pca)\n",
    "classification_rep_knn_pca = classification_report(y_test, y_pred_knn_pca)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Model accuracy: {accuracy_knn_pca:.2f}\")\n",
    "print(classification_rep_knn_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-NN-Modell mit Manhattan-Distanz und PCA-Reduktion auf zwei Komponenten erzielt eine Genauigkeit von 79‚ÄØ%, womit es mit den besten bisher getesteten Modellen mithalten kann.\n",
    "Besonders auff√§llig ist die Leistung bei Klasse 0 (keine KHK) mit einem Recall von 92‚ÄØ%, was bedeutet, dass fast alle gesunden F√§lle korrekt erkannt werden. Die Pr√§zision liegt bei 69‚ÄØ%, was auf einige falsch-positive Vorhersagen hinweist.\n",
    "Klasse 1 (KHK) wird mit einer sehr hohen Pr√§zision von 93‚ÄØ% und einem Recall von 70‚ÄØ% vorhergesagt. Das Modell identifiziert also KHK-F√§lle sehr zuverl√§ssig, √ºbersieht jedoch auch einen Teil davon.\n",
    "\n",
    "Durch die PCA wurde die Dimensionalit√§t stark reduziert. Trotz dieser Vereinfachung bleibt die Leistung auf hohem Niveau, was zeigt, dass die wichtigsten Informationen im Datensatz gut durch die Hauptkomponenten abgebildet werden.\n",
    "Somit ist die anf√§ngliche Aussage, PCA w√§re hinsichtlich der visuellen Analyse wenig aussagekr√§ftig, hinf√§llig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Testen des Feature-Engineering auf einem klassischen Entscheidungsbaum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree model for PCA features\n",
    "clf_tree_pca = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on PCA-transformed features\n",
    "clf_tree_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_tree_pca = clf_tree_pca.predict(X_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_tree_pca = accuracy_score(y_test, y_pred_tree_pca)\n",
    "classification_rep_tree_pca = classification_report(y_test, y_pred_tree_pca)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Model accuracy: {accuracy_tree_pca:.2f}\")\n",
    "print(classification_rep_tree_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Eklassische ntscheidungsbaum-Modell auf den PCA-transformierten Daten erreicht eine Genauigkeit von 70‚ÄØ% und liegt damit deutlich unterhalb des k-NN-Modells mit gleicher Datenbasis.\n",
    "\n",
    "Klasse 0 (keine KHK) wird mit 62‚ÄØ% Pr√§zision und 71‚ÄØ% Recall erkannt ‚Äì gesunde F√§lle werden also mehrheitlich gefunden, aber mit vergleichsweise vielen Fehlalarmen.\n",
    "Klasse 1 (KHK) zeigt mit 77‚ÄØ% Pr√§zision und 68‚ÄØ% Recall etwas bessere Balance, allerdings auf Kosten einer geringeren Sensitivit√§t.\n",
    "\n",
    "Insgesamt wirkt das Modell instabiler, was bei Entscheidungsb√§umen typisch ist, besonders bei reduzierter Datenkomplexit√§t wie nach PCA:\n",
    "\n",
    "\"Unstable: Decision trees can be unstable, as small changes in the data can result in significant changes to the tree structure.\" (vgl. https://lazyprogrammer.me/mlcompendium/supervised/decision_trees.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
