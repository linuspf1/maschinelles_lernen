{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendung von maschinellem Lernen auf den KHK_Klassifikation.csv Datensatz\n",
    "\n",
    "## Praktische Demonstration f√ºr verschiedene machine Learning Modelle\n",
    "\n",
    "### Tim Bleicher, Linus Pfeifer\n",
    "\n",
    "Dieses Jupyter Notebook demonstriert die Anwendung von verschiedenen Machine Learning Modellen auf den KHK_Klassifikation.csv Datensatz. \n",
    "\n",
    "# Inhaltsverzeichnis\n",
    "\n",
    "## 1. Einbindung der Daten\n",
    "- **1.1 Explorative Analyse der Daten**\n",
    "\n",
    "## 2. PCA-Dimensionsreduzierung zur Visualisierung und Analyse der Daten\n",
    "- **Funktionsweise von PCA**\n",
    "- **L√§sst sich aus den PCA-Daten eine potentielle gute Separierbarkeit der Klassen ablesen?**\n",
    "\n",
    "## 3. Anwendung verschiedener Klassifikationsverfahren\n",
    "- **Definition und Datenvorbereitung**\n",
    "- **3.1 Logistische Regression**\n",
    "  - 3.1.1 Modell definieren und trainieren\n",
    "  - 3.1.2 Modell testen\n",
    "- **3.2 Entscheidungsb√§ume**\n",
    "  - 3.2.1 Klassische Entscheidungsb√§ume\n",
    "  - 3.2.2 Bagging in Form von Random Forest\n",
    "  - 3.2.3 Boosting in Form von AdaBoost\n",
    "  - 3.2.4 Stacking\n",
    "- **3.3 k-Nearest-Neighbor**\n",
    "  - 3.3.1 k-Nearest-Neighbor mit euklidischer Metrik\n",
    "  - 3.3.2 k-Nearest-Neighbor mit Manhattan Metrik\n",
    "  - 3.3.3 k-Nearest-Neighbor mit Minkowski Metrik (p = 3)\n",
    "- **3.4 Support Vector Machine**\n",
    "- **3.5 Neuronales Netz**\n",
    "  - 3.5.1 Aktivierungsfunktionen\n",
    "  - 3.5.2 Neuronales Netz mit SGD-Optimizer\n",
    "  - 3.5.3 Neuronales Netz mit Adam-Optimizer\n",
    "\n",
    "## 4. Bedeutung der einzelnen Features\n",
    "- **4.1 Feature-Bedeutung von PCA**\n",
    "- **4.2 Feature-Bedeutung f√ºr Random Forest**\n",
    "- **4.3 Feature-Bedeutung f√ºr SVM**\n",
    "\n",
    "## 5. Feature-Engineering\n",
    "- **5.1 Generieren der PCA-Hauptkomponenten-Daten**\n",
    "- **5.2 Testen des Feature-Engineering auf k-Nearest-Neighbor mit Manhattan Metrik**\n",
    "- **5.3 Testen des Feature-Engineering auf einem klassischen Entscheidungsbaum**\n",
    "\n",
    "## 6. Zusammentragung der Ergebnisse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einbindung der Daten\n",
    "\n",
    "Zu beginn des Projekts werden die Daten zun√§chst geladen um diese im anschluss analysieren und nutzen zu k√∂nnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('KHK_Klassifikation.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to collect classification results\n",
    "results = []\n",
    "\n",
    "\n",
    "def save_results(name, y_true, y_pred, results_list):\n",
    "    \"\"\"Stores accuracy and classification metrics in a list.\"\"\"\n",
    "    accuracy = round(accuracy_score(y_true, y_pred), 3)\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "    results_list.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision_0': round(report['0']['precision'], 3),\n",
    "        'Recall_0': round(report['0']['recall'], 3),\n",
    "        'F1_0': round(report['0']['f1-score'], 3),\n",
    "        'Precision_1': round(report['1']['precision'], 3),\n",
    "        'Recall_1': round(report['1']['recall'], 3),\n",
    "        'F1_1': round(report['1']['f1-score'], 3),\n",
    "        'Macro_F1': round(report['macro avg']['f1-score'], 3)\n",
    "    })\n",
    "\n",
    "    print(f\"Model accuracy: {accuracy:.3f}\")\n",
    "    print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Explorative Analyse der Daten \n",
    "\n",
    "Die explorative Datenanalyse (EDA) ist ein Ansatz zur Untersuchung von Datens√§tzen, bei dem zun√§chst deren Hauptmerkmale visuell und statistisch beschrieben werden ‚Äì oft noch ohne eine konkrete Hypothese. Ziel ist es, ein erstes Verst√§ndnis f√ºr Struktur, Muster, Ausrei√üer, Verteilungen und potenzielle Zusammenh√§nge in den Daten zu bekommen (vgl. https://www.ibm.com/think/topics/exploratory-data-analysis).\n",
    "\n",
    "### üìÑ Beschreibung der Attribute im Datensatz\n",
    "\n",
    "| Attribut      | Beschreibung |\n",
    "|---------------|-------------|\n",
    "| **Alter** | Alter der Patientin oder des Patienten in Jahren. |\n",
    "| **Geschlecht** | Geschlecht der Person: <br>`M` steht f√ºr m√§nnlich, `F` f√ºr weiblich. |\n",
    "| **Blutdruck** | Systolischer Blutdruck in mmHg (Millimeter Quecksilbers√§ule), gemessen im Ruhezustand. Werte ab 140 gelten in der Regel als erh√∂hter Blutdruck. (vgl. https://www.visomat.de/blutdruck-normalwerte/)|\n",
    "| **Chol** | Gesamtcholesterin im Blut in mg/dL (Milligramm pro Deziliter). Erh√∂hte Werte (>190‚ÄØmg/dL) k√∂nnen ein Risiko f√ºr Herz-Kreislauf-Erkrankungen darstellen. (vgl. https://www.cholesterinspiegel.de/auffaellige-cholesterinwerte/) |\n",
    "| **Blutzucker** | N√ºchtern-Blutzuckerwert: <br>`0` = Normaler Blutzucker <br>`1` = Erh√∂hter Blutzucker (m√∂glicher Hinweis auf Diabetes oder Pr√§diabetes). |\n",
    "| **EKG** | Ergebnis des Ruhe-EKGs. M√∂gliche Kategorien: <br>- `Normal` = unauff√§lliger Befund <br>- `ST` = ST-Streckensenkung (Hinweis auf BelastungsischaÃàmie) <br>- `LVH` = Linksventrikul√§re Hypertrophie (Herzmuskelvergr√∂√üerung). |\n",
    "| **HFmax** | Maximale Herzfrequenz (in Schl√§gen pro Minute), die w√§hrend eines Belastungstests erreicht wurde. Sehr grobe Faustregel: HFmax = 220 - Lebensalter (vgl. https://www.germanjournalsportsmedicine.com/archive/archive-2010/heft-12/die-maximale-herzfrequenz/) |\n",
    "| **AP** | Angina Pectoris bei Belastung: <br>`N` = Keine Symptome <br>`Y` = Auftreten von Angina Pectoris (Brustschmerzen unter Belastung), m√∂glicher Hinweis auf Durchblutungsst√∂rungen des Herzens. |\n",
    "| **RZ** | R√ºckgang (bzw. Ver√§nderung) der ST-Strecke w√§hrend eines Belastungs-EKGs in **mm**. <br> Positive Werte deuten auf eine **ST-Streckensenkung** hin, was auf eine m√∂gliche **Isch√§mie des Herzmuskels** (z.‚ÄØB. bei KHK) hindeuten kann. <br> Negative Werte k√∂nnen als **ST-Streckenhebung** interpretiert werden ‚Äì diese k√∂nnen je nach klinischem Zusammenhang normal, unspezifisch oder auch pathologisch sein (z.‚ÄØB. bei Infarkten oder Perikarditis). <br> In der Regel gilt: Je gr√∂√üer der **absolute Betrag**, desto auff√§lliger der Befund. |\n",
    "| **KHK** | **Zielvariable** ‚Äì Diagnose einer koronaren Herzkrankheit: <br>`0` = Keine KHK <br>`1` = KHK nachgewiesen (positives Ergebnis). |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erster Blick auf die Daten:**  \n",
    "Zuerst wird eine Kopie des Datensatzes erstellt und ein erster Blick auf die obersten Zeilen geworfen.\n",
    "Dies dient dazu einen ersten groben √úberblick √ºber die Daten zu bekommen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of the original dataset\n",
    "df = data.copy()\n",
    "\n",
    "# Display the first few rows\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Allgemeine Informationen:**  \n",
    "Mit `df.info()` erh√§lt man einen √úberblick √ºber die Spalten, Datentypen und Anzahl fehlender Werte. Das ist wichtig, um zu verstehen, welche Features numerisch oder kategorisch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General information about the dataset\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistische Kennzahlen:**  \n",
    "Diese √úbersicht zeigt zentrale Lage- und Streuungsma√üe (z.‚ÄØB. Mittelwert, Standardabweichung) f√ºr alle numerischen Spalten. Das hilft, Ausrei√üer oder ungew√∂hnliche Verteilungen fr√ºhzeitig zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical overview of numerical features\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kategoriale Merkmale analysieren:**  \n",
    "Nun wird die H√§ufigkeit der Werte in allen kategorialen Spalten angesehen. So erkennt man dominante Klassen und m√∂gliche Ungleichgewichte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of values for categorical features\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"\\nValue distribution for '{col}':\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fehlende Werte pr√ºfen:**  \n",
    "Hier wird analysiert, in welchen Spalten Daten fehlen. Dies ist entscheidend f√ºr die sp√§tere Datenbereinigung oder Modellierung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doppelte Eintr√§ge identifizieren:**  \n",
    "Es wird gepr√ºft, ob es doppelte Zeilen gibt ‚Äì diese sollten bei Bedarf entfernt werden, um Verzerrungen zu vermeiden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zielvariable analysieren:**  \n",
    "Ein schneller Blick auf die Verteilung der Zielgr√∂√üe (KHK: koronare Herzkrankheit). So sieht man z.‚ÄØB., ob die Klassen unausgeglichen sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target variable (CHD)\n",
    "print(\"\\nDistribution of the target variable 'CHD':\")\n",
    "print(df[\"KHK\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplots zur √úbersicht:**  \n",
    "Boxplots geben einen schnellen √úberblick √ºber die Verteilung numerischer Merkmale inkl. Ausrei√üer. Dies ist besonders hilfreich zum Erkennen von Extremwerten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_cols_filtered = [\n",
    "    col for col in numerical_cols if df[col].nunique() > 2]\n",
    "\n",
    "for col in numerical_cols_filtered:\n",
    "    fig = px.box(df, y=col, points=\"all\",\n",
    "                 title=f\"Boxplot: {col}\", template=\"plotly_white\")\n",
    "    fig.update_layout(yaxis_title=col)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogramme zur Dichteverteilung:**  \n",
    "Diese Plots zeigen, wie sich die Werte in den numerischen Spalten verteilen. Zus√§tzlich ist oben ein Boxplot integriert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_cols_filtered:\n",
    "    fig = px.histogram(df, x=col, nbins=20, marginal=\"box\",\n",
    "                       title=f\"Histogramm: {col}\", template=\"plotly_white\", color_discrete_sequence=[\"steelblue\"])\n",
    "    fig.update_layout(xaxis_title=col, yaxis_title=\"H√§ufigkeit\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplots nach KHK-Klassen:**  \n",
    "Hier wird analysiert, ob sich bestimmte numerische Merkmale in Abh√§ngigkeit von der Zielvariable signifikant unterscheiden. Das kann Hinweise auf relevante Pr√§diktoren liefern.\n",
    "\n",
    "Wichtig zu erw√§hnen ist, dass viele Chol Werte 0 sind, was auf fehlende Daten hinweist. Daher wurden diese Werte herausgefiltert, um die Statistiken nicht zu verf√§lschen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols_khk = [\n",
    "    col for col in numerical_cols\n",
    "    if df[col].nunique() > 2 and col != \"KHK\" and col != \"Blutzucker\"\n",
    "]\n",
    "\n",
    "for col in numerical_cols_khk:\n",
    "    df_plot = df.copy()\n",
    "\n",
    "    # For the Chol column: exclude values with 0\n",
    "    if col == \"Chol\":\n",
    "        df_plot = df_plot[df_plot[\"Chol\"] != 0]\n",
    "\n",
    "    fig = px.box(df_plot, x=\"KHK\", y=col, color=\"KHK\",\n",
    "                 title=f\"{col} by CHD class\", template=\"plotly_white\", points=\"all\")\n",
    "    fig.update_layout(xaxis_title=\"CHD (0 = No, 1 = Yes)\", yaxis_title=col)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA-Dimensionsreduzierung zur Visualisierung und Analyse der Daten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionsweise von PCA\n",
    "Die Hauptkomponentenanalyse (PCA) dient der Dimensionsreduktion eines Datensatzes. Dies erm√∂glicht beispielsweise verschiedene Analyse des gesamten Datensatzes (mit mehr als 3 Dimensionen), wobei die Ergebnisse durch die Dimensionsreduktion weiterhin visualisiert werden k√∂nnen.\n",
    "Das Verfahren der PCA l√§uft nach folgendem Schema ab:\n",
    "\n",
    "1. Berechnung des Mittelwerts und Zentrierung der Daten\n",
    "2. Berechnung der Kovarianzmatrix\n",
    "3. Berechnung der Eigenwerte und Eigenvektoren\n",
    "4. Transformation der Daten\n",
    "\n",
    "Damit die PCA korrekt funktioniert, muss zun√§chst von jeder Dimension der Mittelwert subtrahiert werden. Dieser Mittelwert entspricht dem Durchschnittswert jeder Dimension. Beispielsweise wird von allen $x$-Werten der Mittelwert $\\overline{x}$ subtrahiert. Entsprechendes gilt f√ºr die anderen Dimensionen der Daten. Dadurch entsteht ein Datensatz mit einem Mittelwert von null.\n",
    "\n",
    "Im n√§chsten Schritt wird die Kovarianzmatrix berechnet, welche die wechselseitigen Zusammenh√§nge zwischen den Merkmalen quantifiziert. Falls zwei Merkmale stark korrelieren, k√∂nnen diese in einer neuen Achse kombiniert werden.\n",
    "\n",
    "Anschlie√üend werden die Eigenwerte und Eigenvektoren der Kovarianzmatrix bestimmt. Die Eigenvektoren definieren die Richtungen der Hauptkomponenten, w√§hrend die zugeh√∂rigen Eigenwerte die Bedeutung bzw. die Varianz der jeweiligen Eigenvektoren widerspiegeln.\n",
    "\n",
    "Es folgt die eigentliche Dimensionsreduktion, indem nur diejenigen Eigenvektoren mit den gr√∂√üten Eigenwerten ausgew√§hlt werden. Diese Eigenvektoren entsprechen den neuen Hauptachsen des Datensatzes.\n",
    "\n",
    "Schlie√ülich werden die Daten transformiert, indem die urspr√ºngliche Datenmatrix mit der Matrix der Eigenvektoren multipliziert wird. In dieser Matrix repr√§sentiert jede Spalte einen Eigenvektor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['Geschlecht', 'EKG', 'AP']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    # Encode categorical columns\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target variable \"KHK\" before scaling\n",
    "data_without_target = data.drop(columns=[\"KHK\"], errors=\"ignore\")\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_without_target)\n",
    "\n",
    "# PCA transformation with two principal components\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Convert the PCA results into a DataFrame\n",
    "df_pca = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Interactive visualization\n",
    "fig = px.scatter(df_pca, x='PC1', y='PC2', title='PCA Visualization of the Data', opacity=0.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[\"KHK\"]\n",
    "df_pca['KHK'] = target\n",
    "\n",
    "df_pca['KHK'] = df_pca['KHK'].astype('category')\n",
    "\n",
    "# Interactive visualization with colors based on KHK (0 = blue, 1 = red)\n",
    "fig = px.scatter(\n",
    "    df_pca,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='KHK',\n",
    "    color_discrete_map={0: 'blue', 1: 'red'},  # Discrete color mapping\n",
    "    title='PCA visualization colored by KHK class',\n",
    "    opacity=0.5\n",
    ")\n",
    "\n",
    "# Adjust marker size and legend settings\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.update_layout(\n",
    "    legend_title_text='KHK',  # Clearly label the legend\n",
    "    showlegend=True           # Ensure the legend is displayed\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L√§sst sich aus den PCA-Daten eine potentielle gute Separierbarkeit der Klassen ablesen?\n",
    "\n",
    "Die PCA-Darstellung zeigt eine gewisse Tendenz zur Trennung der Klassen:\n",
    "F√§lle mit KHK (rot) h√§ufen sich eher im linken Bereich, w√§hrend Nicht-KHK-F√§lle (blau) vermehrt im rechten Bereich liegen.\n",
    "Eine klare, saubere Trennung ist aber nicht m√∂glich, aufgrund starken √úberlappungen und Ausrei√üern.\n",
    "Dies liegt vor allem an der Reduktion der Vielzahl an Attributen auf nur 2 Hauptachsen, wobei dann doch zu viele Informationen bei der Darstellung verloren gehen.\n",
    "Sind die Zusammenh√§nge von Attributen nicht-linear (wovon man in diesem Datensatz erstmal ausgehen kann), so gehen wichtige Informationen bei der PCA verloren, da die Abbildung auf den niedrigdimensionalen Raum lediglich linear ist (vgl. Skript ML_10_Dimensionsreduktion S.16-17).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anwendung verschiedener vorgestellter Klassifikationsverfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition und Datenvorbereitung\n",
    "\n",
    "Zun√§chst werden die kategorialen und numerischen Merkmale des Datensatzes definiert. Anschlie√üend erfolgt die Vorbereitung der Daten f√ºr ein Machine-Learning-Modell. Dazu geh√∂ren die Auswahl und Umordnung der Merkmale, die Umwandlung kategorialer Variablen mittels Label-Encoding (vgl. https://kantschants.com/complete-guide-to-encoding-categorical-features), die Standardisierung der numerischen Variablen sowie die Aufteilung in Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical columns\n",
    "categorical_features = [\"Geschlecht\", \"EKG\", \"AP\"]\n",
    "numerical_features = [\"Alter\", \"Blutdruck\", \"Chol\", \"Blutzucker\", \"HFmax\", \"RZ\"]\n",
    "\n",
    "# Select target variable and features\n",
    "X = data[categorical_features + numerical_features].copy()\n",
    "y = data[\"KHK\"]\n",
    "\n",
    "# Reorder features to match the desired order\n",
    "desired_order = [\"Alter\", \"Geschlecht\", \"Blutdruck\", \"Chol\", \"Blutzucker\", \"EKG\", \"HFmax\", \"AP\", \"RZ\"]\n",
    "X = X[desired_order]\n",
    "\n",
    "# Apply Label Encoding to categorical features\n",
    "label_encoders = {}  # Store LabelEncoder objects\n",
    "for col in categorical_features:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    X[col] = label_encoders[col].fit_transform(X[col])\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistische Regression\n",
    "Logistische Regression ist ein statistisches Modell, das den nat√ºrlichen Logarithmus der Chancen eines Ereignisses als lineare Kombination einer oder mehrerer unabh√§ngiger Variablen modelliert.\n",
    "In der Regressionsanalyse sch√§tzt die logistische Regression die Parameter dieses Modells, typischerweise in Szenarien mit einer bin√§ren Zielvariablen (z.‚ÄØB. 0 oder 1) (vgl. https://en.wikipedia.org/wiki/Logistic_regression).\n",
    "\n",
    "Logistische Regression passt gut zu dem Datensatz, da KHK bin√§r ist, der Datensatz gemischte Merkmale enth√§lt und das Modell Wahrscheinlichkeiten f√ºr KHK einfach und interpretierbar berechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Modell definieren und trainieren\n",
    "\n",
    "Das beschriebene logistische Regressionsmodell wird erstellt und mit den Trainingsdaten trainiert, um KHK als bin√§re Zielvariable vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression for binary classification\n",
    "\n",
    "# Create pipeline with preprocessing and logistic regression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Modell testen\n",
    "\n",
    "Das trainierte Modell wird auf den Testdaten angewendet. Die Auswertung erfolgt anhand der **Genauigkeit (Accuracy)** und eines **Classification Reports**, der die wichtigsten Metriken zur Bewertung der Vorhersagequalit√§t enth√§lt:\n",
    "\n",
    "| **Metrik**     | **Beschreibung**                                                                 |\n",
    "|----------------|-----------------------------------------------------------------------------------|\n",
    "| **Accuracy**   | Anteil korrekt klassifizierter Beispiele an allen Beispielen                     |\n",
    "| **Precision**  | Anteil korrekt positiver Vorhersagen an allen als positiv vorhergesagten F√§llen (vgl. https://www.v7labs.com/blog/precision-vs-recall-guide)  |\n",
    "| **Recall**     | Anteil korrekt erkannter positiver F√§lle an allen tats√§chlichen positiven F√§llen (vgl. https://www.v7labs.com/blog/precision-vs-recall-guide) |\n",
    "| **F1-Score**   | Harmonisches Mittel aus Precision und Recall (balanciert beide Metriken) (vgl. https://www.v7labs.com/blog/f1-score-guide)       |\n",
    "\n",
    "Diese Metriken geben gemeinsam ein gutes Bild dar√ºber, wie zuverl√§ssig das Modell bei der KHK-Klassifikation arbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_log_reg = model.predict(X_test)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"Logistische Regression\", y_test, y_pred_log_reg, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die logistische Regression erzielt eine Genauigkeit von 84‚ÄØ% und zeigt insgesamt eine ausgewogene Leistung.  \n",
    "Besonders bei der Erkennung von KHK-F√§llen (Klasse 1) schneidet das Modell gut ab, mit einer Pr√§zision von 85‚ÄØ% und einem Recall von 86‚ÄØ%.  \n",
    "Die Klasse 0 (keine KHK) wird ebenfalls zuverl√§ssig erkannt, mit einer Pr√§zision von 82‚ÄØ% und einem Recall von 81‚ÄØ%.  \n",
    "\n",
    "\n",
    "Insgesamt liefert das Modell stabile und gut ausbalancierte Vorhersagen und eignet sich als verl√§sslicher Basisansatz f√ºr die Klassifikation von KHK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Entscheidungsb√§ume\n",
    "\n",
    "Ein Entscheidungsbaum ist ein geordneter, gerichteter Baum, der Entscheidungsregeln in einer hierarchischen Struktur darstellt\n",
    "Jeder Knoten repr√§sentiert eine Bedingung oder Entscheidungsregel basierend auf einem Merkmal des Datensatzes (vgl. https://de.wikipedia.org/wiki/Entscheidungsbaum).\n",
    "Die Blattknoten am Ende des Baums geben die Vorhersage oder Klassenzugeh√∂rigkeit aus (in unserem Fall KHK = 0 oder 1).\n",
    "Die Struktur erm√∂glicht es, Daten schrittweise entlang dieser Bedingungen aufzuteilen, um zu einer fundierten Entscheidung zu gelangen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Klassische Entscheidungsb√§ume\n",
    "\n",
    "Der klassische Entscheidungsbaum funktioniert wie in [3.2](#32-entscheidungsb√§ume) beschrieben. Es werden keine Ensemble-Methoden verwendet, sondern ein einzelner Baum erstellt, der rekursiv durch Splits an Knotenpunkten aufgebaut wird.\n",
    "\n",
    "Auch hier wird die Klassifikation wieder an den schon beschriebenen Metriken gemessen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree Classifier\n",
    "clf_tree = DecisionTreeClassifier(random_state=42)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_tree = clf_tree.predict(X_test)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"Klassischer Entscheidungsbaum\", y_test, y_pred_tree, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der klassische Entscheidungsbaum erreicht eine Genauigkeit von 70‚ÄØ% und bleibt damit deutlich hinter der logistischen Regression zur√ºck.  \n",
    "W√§hrend KHK-F√§lle (Klasse 1) mit einer Pr√§zision von 74‚ÄØ% und einem F1-Score von 0.73 passabel erkannt werden, zeigt das Modell bei der Klasse 0 (keine KHK) leichte Schw√§chen, insbesondere bei der Pr√§zision mit nur 66‚ÄØ%.  \n",
    "\n",
    "F√ºr den vorliegenden Datensatz liefert der klassische Entscheidungsbaum somit eine solide, aber nicht √ºberlegene Vorhersagequalit√§t und generalisiert etwas schlechter als das lineare Modell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Bagging in Form von Random Forest\n",
    "Random Forest ist ein Modell, das viele Entscheidungsb√§ume kombiniert. Jeder Baum wird auf zuf√§lligen Daten und Merkmalen trainiert.\n",
    "Die Vorhersagen der B√§ume werden am Ende zusammengefasst (beispielsweise per Mehrheitsentscheid). Dadurch wird das Modell stabiler und genauer als ein einzelner Baum (vgl. https://www.ibm.com/de-de/think/topics/random-forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_random_forest = clf.predict(X_test)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"Random Forest\", y_test, y_pred_random_forest, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Random Forest erzielt eine Genauigkeit von 83‚ÄØ% und liegt damit leicht unterhalb der logistischen Regression, aber deutlich √ºber dem einfachen Entscheidungsbaum.\n",
    "Die Klasse 1 (KHK) wird mit einer Pr√§zision von 86‚ÄØ% und einem Recall von 82‚ÄØ% sehr zuverl√§ssig erkannt. Auch Klasse 0 (keine KHK) erreicht solide Werte mit 79‚ÄØ% Pr√§zision und 83‚ÄØ% Recall.\n",
    "Insgesamt zeigt das Modell eine ausgewogene Leistung mit guter Generalisierungsf√§higkeit.\n",
    "\n",
    "Dadurch, dass viele Entscheidungsb√§ume kombiniert werden, kann Random Forest wohl komplexere Zusammenh√§nge gut erfassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Boosting in Form von AdaBoost\n",
    "\n",
    "Adaptive Boosting ist einer der bekanntesten und breitesten Boosting Algorithmen.\n",
    "Mehrere schwache Modelle werden nacheinander trainiert, wobei jedes neue Modell gezielt die Fehler der vorherigen korrigiert, indem falsch klassifizierte Daten st√§rker gewichtet werden. Die endg√ºltige Vorhersage entsteht durch ein gewichtetes Mehrheitsvotum(vgl. Skript ML_08_Modelle-V S.26-34).\n",
    "Die Anzahl der Einzelmodelle (n_estimators) bestimmt, wie viele Iterationen durchgef√ºhrt werden. Die Lernrate (learning_rate) steuert, wie stark sich jedes neue Modell auf das Gesamtergebnis auswirken soll.\n",
    "Eine zu hohe Lernrate kann zu √úberanpassung f√ºhren, w√§hrend eine zu niedrige Rate den Lernprozess verlangsamen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Train AdaBoost model with specified parameters\n",
    "adaboost_model = AdaBoostClassifier(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ada = adaboost_model.predict(X_test)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"AdaBoost\", y_test, y_pred_ada, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das AdaBoost-Modell erreicht eine Genauigkeit von 85‚ÄØ% und liefert damit das (in der chronologischen Reihenfolge des Notebooks) bislang beste Ergebnis unter den getesteten Verfahren.  \n",
    "Die Klasse 0 (keine KHK) wird mit einer Pr√§zision von 82‚ÄØ% und einem Recall von 86‚ÄØ% solide erkannt, w√§hrend die Klasse 1 (KHK) mit 88‚ÄØ% Pr√§zision und 84‚ÄØ% Recall besonders zuverl√§ssig vorhergesagt wird.\n",
    "\n",
    "Durch das schrittweise Lernen aus Fehlern fr√ºherer Modelle gelingt AdaBoost eine gut ausbalancierte Klassifikation, die sowohl Pr√§zision als auch Sensitivit√§t ber√ºcksichtigt. Im Vergleich zur logistischen Regression und zum Random Forest schneidet AdaBoost leicht besser ab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Stacking\n",
    "\n",
    "Stacking kombiniert verschiedene Modelle, die jeweils unterschiedliche Bereiche der Merkmalsverteilung gut abdecken, und nutzt deren Vorhersagen gemeinsam, um die Gesamtvorhersage zu verbessern (vgl. Skript ML_08_Modelle-V S.40-42).\n",
    "Es ist besondern gut anzuwenden, wenn die Einzelmodelle ausreichend verschieden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base models: KNN, SVM, and Logistic Regression\n",
    "base_estimators = [\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=35)),  # KNN with 5 neighbors\n",
    "    ('svc', SVC(kernel='rbf', random_state=42)),  # SVM with a linear kernel\n",
    "    ('logreg', LogisticRegression(random_state=42))  # Logistic Regression\n",
    "]\n",
    "\n",
    "# Final model (meta-model)\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# Create StackingClassifier with base models and final estimator\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_estimators, final_estimator=final_estimator)\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"Stacking\", y_test, y_pred_stack, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Stacking-Modell erreicht eine Genauigkeit von 85‚ÄØ% und liegt damit in etwa auf dem Niveau des AdaBoost-Modells. Es kombiniert KNN, SVM und logistische Regression als Basis-Modelle und nutzt erneut eine logistische Regression als Meta-Modell, das aus den Vorhersagen der einzelnen Basis-Modelle lernt.\n",
    "\n",
    "F√ºr Klasse 0 (keine KHK) wird eine Pr√§zision von 82‚ÄØ% und ein Recall von 85‚ÄØ% erzielt, w√§hrend f√ºr Klasse 1 (KHK) eine Pr√§zision von 87‚ÄØ% und ein Recall von 85‚ÄØ% erreicht wird.\n",
    "\n",
    "Insgesamt zeigt das Modell eine ausgewogene Performance, die auf die Vielfalt der Basismodelle und ihre geschickte Kombination zur√ºckzuf√ºhren ist. Dennoch liegt es minimal unter dem vorherigen AdaBoost-Modell, das eine etwas bessere Gesamtleistung erbracht hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 k-Nearest-Neighbor\n",
    "KNN ist ein einfacher Algorithmus, der neue Datenpunkte anhand der k √§hnlichsten bekannten Punkte einordnet.\n",
    "Er speichert nur die Trainingsdaten und trifft Entscheidungen bei der Vorhersage, basierend auf dem Abstand zu den n√§chsten Nachbarn (vgl. https://www.ibm.com/de-de/think/topics/knn). *n_neigbors* wurde im Rahmen dieses Projekts durch das Testen f√ºr die jeweilige Metrik festgelegt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 k-Nearest-Neighbor mit euklidischer Metrik\n",
    "\n",
    "Es wird der direkte Abstand zwischen zwei Punkten im Merkmalsraum gemessen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 and Euclidean distance metric\n",
    "knn_model = KNeighborsClassifier(n_neighbors=25, metric='euclidean')\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"k-NN (euklidisch)\", y_test, y_pred_knn, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-NN-Modell mit euklidischer Distanz erreicht eine Genauigkeit von 84‚ÄØ% und liegt damit unter dem AdaBoost-Modell, das eine Genauigkeit von 85‚ÄØ% erzielt jedoch auf einem Niveau mit der logistischen Regression. Besonders auff√§llig ist die Leistung bei Klasse 0 (keine KHK): Mit einem Recall von 86‚ÄØ% erkennt das Modell sehr zuverl√§ssig gesunde F√§lle, auch wenn die Pr√§zision bei 79‚ÄØ% liegt. F√ºr Klasse 1 (KHK) ist die Pr√§zision mit 88‚ÄØ% sogar noch h√∂her, aber der Recall etwas niedriger bei 82‚ÄØ%.\n",
    "\n",
    "Insgesamt zeigt sich ein leichtes Ungleichgewicht: Das Modell erkennt gesunde Patienten sicher, neigt aber dazu, einige KHK-F√§lle zu √ºbersehen.  \n",
    "Dennoch ist die F1-Balance gut und das Modell profitiert offenbar davon, dass k-NN bei gut strukturierten Daten (StandardScaler()) effektiv trennen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 k-Nearest-Neighbor mit manhattan Metrik\n",
    "\n",
    "Es wird der Abstand zwischen zwei Punkten als Summe der absoluten Differenzen der Merkmalswerte berechnet (Analogie zu rechteckigen Stra√üennetzen).\n",
    "Dies erm√∂glicht h√∂here Robustheit gegen Ausrei√üer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 and Manhattan distance metric\n",
    "knn_model = KNeighborsClassifier(n_neighbors=30, metric='manhattan')\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"k-NN (Manhattan)\", y_test, y_pred_knn, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-NN-Modell mit Manhattan-Distanz erreicht eine Genauigkeit von 86‚ÄØ% und liefert damit die bisher beste Gesamtleistung aller getesteten Modelle.  \n",
    "F√ºr Klasse 0 (keine KHK) erzielt das Modell einen sehr hohen Recall von 89‚ÄØ%, was bedeutet, dass nahezu alle gesunden F√§lle erkannt werden, w√§hrend die Pr√§zision bei 80‚ÄØ% liegt. F√ºr Klasse 1 (KHK) wird eine Pr√§zision von 91‚ÄØ% und ein Recall von 82‚ÄØ% erreicht.\n",
    "\n",
    "Die Verwendung der Manhattan-Metrik scheint hier besonders gut zu den strukturellen Eigenschaften des Datensatzes zu passen. Sie reagiert robuster auf einzelne Ausrei√üer in den Merkmalen und erm√∂glicht dadurch eine pr√§zisere Trennung zwischen den Klassen. Insgesamt zeigt das Modell, dass eine gezielte Anpassung der Distanzmetrik zu einer verbesserten Vorhersagequalit√§t f√ºhren kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 k-Nearest-Neighbor mit Minkowski Metrik und p = 3\n",
    "\n",
    "Die Minkowski Metrik kann √ºber den Parameter p verschiedene Distanzen annehmen.\n",
    "p = 3 deutet den √úbergang zwischen euklidischen und Tschebyscheff-Abst√§nden an (vgl. https://www.datacamp.com/de/tutorial/minkowski-distance).\n",
    "Hierbei werden Abst√§nde bei Gr√∂√üeren Unterschieden st√§rker betont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 and Minkowski distance metric (p=3)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=17, metric='minkowski', p=3)\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"k-NN (Minkowski, p=3)\", y_test, y_pred_knn, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-NN-Modell mit Minkowski-Distanz erreicht eine Genauigkeit von 83‚ÄØ% und liegt damit im mittleren bis oberen Leistungsbereich der bisher getesteten Verfahren.  \n",
    "F√ºr Klasse 0 (keine KHK) liegt die Pr√§zision bei 80‚ÄØ% und der Recall bei 83‚ÄØ%, w√§hrend Klasse 1 (KHK) mit 86‚ÄØ% Pr√§zision und 84‚ÄØ% Recall solide vorhergesagt wird.\n",
    "\n",
    "Wie schon in der Beschreibung von [3.3.4](#334-k-nearest-neighbor-mit-minkowski-metrik-und-p-3) angesprochen, bewirkt die Wahl von p = 3 bei der Minkowski-Metrik, dass gr√∂√üere Unterschiede zwischen Merkmalswerten st√§rker ins Gewicht fallen als bei der euklidischen (p = 2) oder Manhattan-Distanz (p = 1). Dies kann dazu f√ºhren, dass das Modell besonders empfindlich auf markante Auspr√§gungen einzelner Merkmale reagiert ‚Äì was hilfreich sein kann, wenn solche Ausrei√üer tats√§chlich relevant sind. Allerdings kann diese erh√∂hte Sensitivit√§t auch zu Fehleinsch√§tzungen f√ºhren, wenn die betonten Unterschiede nicht entscheidend f√ºr die Klassifizierung sind.\n",
    "\n",
    "Geht p gegen unendlich, spricht man von der Tschebyscheff-Distanz, welche ausschlie√ülich den gr√∂√üten Unterschied zwischen zwei Merkmalen misst. Aufgrund dieser Eigenschaft reagiert die Tschebyscheff-Metrik sehr empfindlich gegen√ºber einzelnen Ausrei√üern, was im medizinischen Kontext schnell zu Fehlentscheidungen f√ºhren kann.\n",
    "\n",
    "Insgesamt bietet das Modell mit p = 3 eine ausgewogene Performance, die in etwa mit den Varianten unter Verwendung der euklidischen oder Manhattan-Distanz vergleichbar ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Support Vector Machine\n",
    "\n",
    "SVM ist ein supervised Klassifikationsverfahren, das eine Hyperebene mit dem gr√∂√ütm√∂glichen Abstand zwischen zwei Klassen findet.\n",
    "Wichtig sind dabei die Support-Vektoren, die die Trennung bestimmen.\n",
    "SVMs sind leistungsstark, aber oft schwer interpretierbar und rechenintensiv. Mit Soft-Margin k√∂nnen auch nicht perfekt trennbare Daten verarbeitet werden (vgl. Skript ML_07_Modelle-IV S.41-49).\n",
    "\n",
    "Der hier verwendete rbf (radial basis function) Kernel ist ein nicht linearer Kernel, der die Daten eben nicht nur linear separieren kann, sondern Entscheidungsgrenzen beliebiger Form finden kann. Daf√ºr werden die Daten in einen h√∂herdimensionalen Raum transformiert (vgl. https://doi.org/10.1016/j.jfranklin.2021.10.005)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM model with a rbf kernel\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"SVM (rbf)\", y_test, y_pred_svm, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das SVM-Modell erreicht eine Genauigkeit von 86‚ÄØ% und liefert damit ein gutes Ergebnis, vergleichbar mit AdaBoost und den besten k-NN-Varianten.\n",
    "Die Klasse 0 (keine KHK) wird mit 86‚ÄØ% Recall gut erkannt, bei einer Pr√§zision von 82‚ÄØ%.\n",
    "Klasse 1 (KHK) zeigt eine hohe Pr√§zision von 88‚ÄØ% bei solidem Recall von 85‚ÄØ%. Das Modell identifiziert KHK-F√§lle also sehr zuverl√§ssig.\n",
    "\n",
    "Da ein RBF-Kernel verwendet wird, zeigt das gute Ergebnis, dass das Modell in der Lage ist, komplexe nichtlineare Zusammenh√§nge in den Daten zu erfassen.\n",
    "Gleichzeitig bleibt die Balance von Pr√§zision und Recall erhalten, was f√ºr die Effektivit√§t dieser Kernel-Wahl spricht (vgl. https://www.ibm.com/think/topics/support-vector-machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Neuronales Netz\n",
    "\n",
    "Ein neuronales Netz besteht aus mehreren Schichten k√ºnstlicher Neuronen, die √ºber gewichtete Verbindungen Informationen weitergeben.\n",
    "Ein Neuron wird aktiviert, wenn sein Output einen Schwellenwert √ºberschreitet. So lernt das Netz, Muster in Daten zu erkennen (vgl. https://www.ibm.com/de-de/topics/neural-networks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1 Aktivierungsfunktionen\n",
    "ReLu (Rectified Linear Unit): gibt nur positive Werte weiter, negative werden zu null. Dadurch bleibt das Netzwerk recheneffizient, und nur wichtige Neuronen werden aktiviert. Das hilft dem Modell beim schnellen und stabilen Lernen (vgl. https://www.ultralytics.com/de/glossary/relu-rectified-linear-unit).\n",
    "\n",
    "Sigmoid: wandelt jeden beliebigen Wert in einen Bereich zwischen 0 und 1 um. Es ergibt sich eine S-Kurve. Sigmoid wird h√§ufig genutzt um Ausgaben als Wahrscheinlichkeiten abzubilden (vgl. https://deepai.org/machine-learning-glossary-and-terms/sigmoid-function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer):\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # First hidden layer\n",
    "        Dense(32, activation='relu'),  # Second hidden layer\n",
    "        Dense(16, activation='relu'),  # Third hidden layer\n",
    "        Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,  # Set optimizer\n",
    "                  loss='binary_crossentropy',  # Loss function for binary classification\n",
    "                  metrics=['accuracy'])  # Metrics to track during training\n",
    "\n",
    "    # Display model summary\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Neuronales Netz mit SGD-Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using the SGD optimizer\n",
    "sgd_model = create_model(optimizer='sgd')\n",
    "\n",
    "# Train the model\n",
    "history_sgd = sgd_model.fit(X_train, y_train,\n",
    "                            epochs=50,  # Number of epochs for training\n",
    "                            batch_size=32,  # Batch size for training\n",
    "                            validation_split=0.2,  # Split of training data for validation\n",
    "                            verbose=1)  # Display progress during training\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss_sgd, test_accuracy_sgd = sgd_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Visualize training history with Plotly\n",
    "\n",
    "# Plot Accuracy\n",
    "fig_accuracy = go.Figure()\n",
    "fig_accuracy.add_trace(go.Scatter(x=list(range(1, 51)), y=history_sgd.history['accuracy'],\n",
    "                                 mode='lines', name='Training Accuracy'))\n",
    "fig_accuracy.add_trace(go.Scatter(x=list(range(1, 51)), y=history_sgd.history['val_accuracy'],\n",
    "                                 mode='lines', name='Validation Accuracy'))\n",
    "\n",
    "fig_accuracy.update_layout(\n",
    "    title='Model Accuracy',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Accuracy'\n",
    ")\n",
    "\n",
    "# Plot Loss\n",
    "fig_loss = go.Figure()\n",
    "fig_loss.add_trace(go.Scatter(x=list(range(1, 51)), y=history_sgd.history['loss'],\n",
    "                             mode='lines', name='Training Loss'))\n",
    "fig_loss.add_trace(go.Scatter(x=list(range(1, 51)), y=history_sgd.history['val_loss'],\n",
    "                             mode='lines', name='Validation Loss'))\n",
    "\n",
    "fig_loss.update_layout(\n",
    "    title='Model Loss',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss'\n",
    ")\n",
    "\n",
    "# Show the figures\n",
    "fig_accuracy.show()\n",
    "fig_loss.show()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "y_pred_classes_sgd = (y_pred_sgd > 0.5).astype(int)  # Convert probabilities to binary classes\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"Neural Net (SGD)\", y_test, y_pred_classes_sgd, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** Neuronale Netze liefern nicht immer identische Ergebnisse, da Gewichte zuf√§llig initialisiert und Trainingsdaten zuf√§llig gemischt werden. Die folgenden Werte und Erkenntnisse k√∂nnen bei erneuter Ausf√ºhrung abweichen, liegen aber bestenfalls nahe an den hier gezeigten.\n",
    "\n",
    "**Grafische Analyse**\n",
    "\n",
    "Die beiden dargestellten Graphen zeigen den Verlauf von Genauigkeit (Accuracy) und Verlust (Loss) √ºber 50 Trainings-Epochen. In der oberen Grafik ist zu erkennen, dass die Trainingsgenauigkeit kontinuierlich steigt und gegen Ende Werte um 84‚ÄØ% erreicht. Die Validierungsgenauigkeit verbessert sich zun√§chst ebenfalls, stagniert aber ab etwa Epoche 15 und pendelt sich dann bei etwa 74‚Äì75‚ÄØ% ein. Die wachsende L√ºcke zwischen Trainings- und Validierungsgenauigkeit deutet auf ein beginnendes Overfitting hin.\n",
    "\n",
    "In der unteren Grafik zum Loss zeigt sich ein √§hnliches Bild: Der Trainingsverlust sinkt kontinuierlich und gleichm√§√üig bis auf unter 0,4, w√§hrend der Validierungsverlust etwa ab Epoche 20 nicht weiter sinkt und sich bei ca. 0,53 stabilisiert. Auch hier ist eine deutliche Trennung zwischen Training und Validierung sichtbar, was die Vermutung von Overfitting best√§tigt.\n",
    "\n",
    "**Statistische Analyse**\n",
    "\n",
    "Auf dem Testdatensatz erreicht das neuronale Netz eine Genauigkeit von 84‚ÄØ%, was mit den besten klassischen Verfahren wie SVM, AdaBoost oder k-NN vergleichbar ist.\n",
    "Die Klasse 1 (KHK) wird besonders zuverl√§ssig erkannt, mit einer Pr√§zision von 86‚ÄØ% und einem Recall von 84‚ÄØ%. Das bedeutet, dass wenige gesunde Patienten f√§lschlich als krank eingestuft und auch die meisten tats√§chlichen KHK-F√§lle korrekt erkannt werden.\n",
    "\n",
    "Die Klasse 0 (keine KHK) wird mit einer Pr√§zision von 81‚ÄØ% und einem Recall von 83‚ÄØ% solide erfasst. Die F1-Scores von 82‚ÄØ% (Klasse 0) und 85‚ÄØ% (Klasse 1) deuten auf eine ausgewogene Gesamtleistung hin, ohne starke Verzerrung zugunsten einer Klasse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3 Neuronales Netz mit Adam-Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using the Adam optimizer\n",
    "adam_model = create_model(optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "history_adam = adam_model.fit(X_train, y_train,\n",
    "                              epochs=50,  # Number of epochs for training\n",
    "                              batch_size=32,  # Batch size for training\n",
    "                              validation_split=0.2,  # Split of training data for validation\n",
    "                              verbose=1)  # Display progress during training\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy_adam = adam_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Visualize training history with Plotly\n",
    "\n",
    "# Plot Accuracy\n",
    "fig_accuracy_adam = go.Figure()\n",
    "fig_accuracy_adam.add_trace(go.Scatter(x=list(range(1, 51)), y=history_adam.history['accuracy'],\n",
    "                                      mode='lines', name='Training Accuracy'))\n",
    "fig_accuracy_adam.add_trace(go.Scatter(x=list(range(1, 51)), y=history_adam.history['val_accuracy'],\n",
    "                                      mode='lines', name='Validation Accuracy'))\n",
    "\n",
    "fig_accuracy_adam.update_layout(\n",
    "    title='Model Accuracy',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Accuracy'\n",
    ")\n",
    "\n",
    "# Plot Loss\n",
    "fig_loss_adam = go.Figure()\n",
    "fig_loss_adam.add_trace(go.Scatter(x=list(range(1, 51)), y=history_adam.history['loss'],\n",
    "                                  mode='lines', name='Training Loss'))\n",
    "fig_loss_adam.add_trace(go.Scatter(x=list(range(1, 51)), y=history_adam.history['val_loss'],\n",
    "                                  mode='lines', name='Validation Loss'))\n",
    "\n",
    "fig_loss_adam.update_layout(\n",
    "    title='Model Loss',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss'\n",
    ")\n",
    "\n",
    "# Show the figures\n",
    "fig_accuracy_adam.show()\n",
    "fig_loss_adam.show()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_adam = adam_model.predict(X_test)\n",
    "y_pred_classes_adam = (y_pred_adam > 0.5).astype(int)  # Convert probabilities to binary classes\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"Neural Net (Adam)\", y_test, y_pred_classes_adam, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** Neuronale Netze liefern nicht immer identische Ergebnisse, da Gewichte zuf√§llig initialisiert und Trainingsdaten zuf√§llig gemischt werden. Die folgenden Werte und Erkenntnisse k√∂nnen bei erneuter Ausf√ºhrung abweichen, liegen aber bestenfalls nahe an den hier gezeigten.\n",
    "\n",
    "**Grafische Analyse**\n",
    "\n",
    "In der oberen Grafik ist der Verlauf der Trainings- und Validierungsgenauigkeit zu sehen. Das Modell erreicht bereits nach wenigen Epochen sehr gute Werte: Die Trainingsgenauigkeit steigt weiter bis etwa 89‚ÄØ%, w√§hrend sich die Validierungsgenauigkeit fr√ºh bei etwa 74‚ÄØ% stabilisiert. Ab Epoche 10 ist eine deutliche L√ºcke zwischen beiden Kurven zu erkennen, was klar auf Overfitting hinweist.\n",
    "\n",
    "In der unteren Grafik wird dieser Eindruck best√§tigt: Der Trainings-Loss sinkt stetig bis auf ca. 0.27, w√§hrend der Validierungs-Loss ab Epoche 3 nur noch schwach variiert und sp√§ter sogar ansteigt, auf bis zu ca. 0.65 gegen Ende des Trainings. Auch hier ist zu sehen, dass sich das Modell zu stark auf die Trainingsdaten einstellt.\n",
    "\n",
    "Ein fr√ºheres Stoppen (Early Stopping) w√§re sinnvoll, um das beginnende Overfitting zu verhindern.\n",
    "\n",
    "**Statistische Analyse**\n",
    "\n",
    "Das Modell erzielt eine Genauigkeit von 84‚ÄØ% auf dem Testdatensatz, was ein solides Ergebnis darstellt. Die Leistung ist damit vergleichbar mit anderen starken Verfahren wie logistische Regression oder k-NN mit euklidischer Metrik.\n",
    "Klasse 0 (keine KHK) wird mit 79‚ÄØ% Pr√§zision und 87‚ÄØ% Recall erkannt, Klasse 1 (KHK) mit 89‚ÄØ% Pr√§zision und 81‚ÄØ% Recall. Das Modell erfasst KHK-F√§lle somit zuverl√§ssiger als gesunde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bedeutung der einzelnen Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature-Bedeutung von PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names (excluding the target variable \"KHK\")\n",
    "feature_names = data.columns.tolist()\n",
    "feature_names.remove(\"KHK\")\n",
    "\n",
    "# Compute the importance of features from PCA components\n",
    "feature_importance = np.abs(pca.components_).sum(axis=0)\n",
    "\n",
    "# Create DataFrame for Plotly visualization\n",
    "df_plot = pd.DataFrame({\"Feature\": feature_names, \"Wichtigkeit\": feature_importance})\n",
    "\n",
    "# Create an interactive bar plot with Plotly\n",
    "fig = px.bar(df_plot, x=\"Feature\", y=\"Wichtigkeit\", title=\"Feature Importance from PCA\", labels={\"Feature\": \"Feature\", \"Wichtigkeit\": \"Feature Importance\"})\n",
    "fig.update_xaxes()  # Update x-axis for better readability\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die PCA-basierte Feature-Wichtigkeit zeigt, dass Chol, RZ und AP besonders stark zur Struktur der Hauptkomponenten beitragen. Diese Merkmale sind bereits in der explorativen Analyse aufgefallen. Weniger Einfluss auf die PCA haben dagegen EKG und Geschlecht. Dabei ist zu beachten, dass PCA nur die Varianz in den Daten abbildet. Die hier gezeigte Wichtigkeit bezieht sich also auf die Datenstruktur, nicht direkt auf die Relevanz f√ºr die KHK-Klassifikation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature-Bedeutung f√ºr Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importance from the Random Forest model\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Create DataFrame for Plotly visualization\n",
    "df_plot = pd.DataFrame({\"Feature\": X.columns.tolist(), \"Wichtigkeit\": feature_importance})\n",
    "\n",
    "# Create an interactive bar plot with Plotly\n",
    "fig = px.bar(df_plot, x=\"Feature\", y=\"Wichtigkeit\", title=\"Feature Importance from Random Forest\", labels={\"Feature\": \"Feature\", \"Wichtigkeit\": \"Feature Importance\"})\n",
    "fig.update_xaxes()  # Update x-axis for better readability\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Feature-Wichtigkeit des Random-Forest-Modells zeigt, dass Chol, AP, RZ und HFmax zu den wichtigsten Merkmalen f√ºr die Klassifikation von KHK geh√∂ren.\n",
    "Diese Merkmale erhalten vom Modell die h√∂chste Gewichtung bei der Entscheidungsfindung. Alter und Blutdruck sind ebenfalls relevant, w√§hrend Blutzucker, EKG und Geschlecht im Vergleich deutlich weniger Einfluss haben.\n",
    "Im Gegensatz zur vorherigen PCA basiert diese Bewertung direkt auf der F√§higkeit der Merkmale, zur Vorhersage der Zielvariable (KHK) beizutragen, und ist damit aussagekr√§ftiger f√ºr die Modellinterpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Bedeutung SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne Permutations-Feature-Wichtigkeit\n",
    "result = permutation_importance(svm_model, X, y, n_repeats=10, random_state=42)\n",
    "\n",
    "# Feature-Wichtigkeiten extrahieren\n",
    "feature_importance = result.importances_mean\n",
    "\n",
    "# Erstelle DataFrame f√ºr die Visualisierung\n",
    "df_plot = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Wichtigkeit\": feature_importance\n",
    "})\n",
    "\n",
    "\n",
    "# Erstelle interaktives Bar-Plot mit Plotly\n",
    "fig = px.bar(df_plot, x=\"Feature\", y=\"Wichtigkeit\", title=\"Feature Importance (Permutation, SVM-RBF)\", labels={\"Feature\": \"Feature\", \"Wichtigkeit\": \"Feature Importance\"})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Feature-Wichtigkeit der SVM mit RBF-Kernel zeigt, dass AP einen deutlich st√§rkeren Einfluss auf die Entscheidung des Modells hat als alle anderen Merkmale. Auch RZ, HFmax und Chol tragen sp√ºrbar zur Modellentscheidung bei. Merkmale wie Geschlecht, Blutdruck und EKG haben hingegen nur einen sehr geringen Einfluss auf das Klassifikationsergebnis.\n",
    "\n",
    "Da beim RBF-Kernel keine direkt interpretierbaren Koeffizienten wie bei der linearen SVM vorliegen, basiert die Bewertung hier auf Permutation Feature Importance. Diese Methode misst, wie stark sich das Modell verschlechtert, wenn einzelne Merkmale zuf√§llig permutiert werden(vgl. https://christophm.github.io/interpretable-ml-book/feature-importance.html). Je st√§rker der Leistungsverlust, desto wichtiger das Feature. Die Bedeutung ergibt sich also nicht aus der Modellstruktur selbst, sondern aus dem Einfluss auf die Modellleistung.\n",
    "\n",
    "Zusammenfassend l√§sst sich sagen, dass je nach gew√§hltem Verfahren andere Werte ausschlaggebend f√ºr die Klassifikation sind.\n",
    "Chol, sowie AP und RZ sind jedoch bei den drei gezeigten Graphen stets von hoher Relevanz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature-Engineering\n",
    "\n",
    "F√ºr das Feature Engineering wurden zwei Klassifikationsverfahren ausgew√§hlt. Einmal wurde k-Nearest-Neighbor mit Manhattan Metrik genutzt und zus√§tzlich klassische Entscheidungsb√§ume. Diese beiden Klassifikationsverfahren wurden ausgew√§hlt, dass k-Nearest-Neighbor mit Manhattan Metrik beim testen die h√∂chste und klassische Entscheidungsb√§ume die schlechteste Genauigkeit hatten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Generieren der PCA-Hauptkomponenten Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of principal components to keep (can be adjusted)\n",
    "pca_components = 5\n",
    "\n",
    "# Perform PCA transformation with the specified number of components\n",
    "pca = PCA(n_components=pca_components)\n",
    "X_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Convert the PCA results into a DataFrame\n",
    "df_pca = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(pca_components)])\n",
    "\n",
    "# Add the target variable \"KHK\" to the PCA DataFrame\n",
    "df_pca['KHK'] = data['KHK'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(df_pca.drop(columns=[\"KHK\"]), df_pca[\"KHK\"], test_size=0.3, random_state=42, shuffle=True, stratify=df_pca[\"KHK\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Testen des Feature-Engineering auf k-Nearest-Neighbor mit Manhattan Metrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-NN model with k=10 for PCA features using Manhattan distance\n",
    "knn_model_pca = KNeighborsClassifier(n_neighbors=34, metric='manhattan')\n",
    "\n",
    "# Train the model on PCA-transformed features\n",
    "knn_model_pca.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn_pca = knn_model_pca.predict(X_test_pca)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"k-NN (PCA + Manhattan)\", y_test_pca, y_pred_knn_pca, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das k-NN-Modell mit Manhattan-Distanz und PCA-Reduktion auf zwei Komponenten erzielt eine Genauigkeit von 84‚ÄØ%, womit es mit den besten bisher getesteten Modellen mithalten kann.\n",
    "Besonders auff√§llig ist die Leistung bei Klasse 0 (keine KHK) mit einem Recall von 88‚ÄØ%, was bedeutet, dass fast alle gesunden F√§lle korrekt erkannt werden. Die Pr√§zision liegt bei 79‚ÄØ%, was auf einige falsch-positive Vorhersagen hinweist.\n",
    "Klasse 1 (KHK) wird mit einer sehr hohen Pr√§zision von 89‚ÄØ% und einem Recall von 82‚ÄØ% vorhergesagt. Das Modell identifiziert also KHK-F√§lle sehr zuverl√§ssig, √ºbersieht jedoch auch einen Teil davon.\n",
    "\n",
    "Durch die PCA wurde die Dimensionalit√§t stark reduziert. Trotz dieser Vereinfachung bleibt die Leistung auf hohem Niveau, was zeigt, dass die wichtigsten Informationen im Datensatz gut durch die Hauptkomponenten abgebildet werden.\n",
    "Dies best√§tigt die anf√§ngliche Annahme, dass PCA zum Teil die Daten sinnvoll separieren kann.\n",
    "Das k-NN Modell ohne PCA hat jedoch trotzdem eine h√∂here Genauigkeit mit 86 %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Testen des Feature-Engineering auf einem klassischen Entscheidungsbaum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree model for PCA features\n",
    "clf_tree_pca = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on PCA-transformed features\n",
    "clf_tree_pca.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_tree_pca = clf_tree_pca.predict(X_test_pca)\n",
    "\n",
    "# Save results using the helper function\n",
    "save_results(\"Klassischer Entscheidungsbaum (PCA)\", y_test_pca, y_pred_tree_pca, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das klassische Entscheidungsbaum-Modell auf den PCA-transformierten Daten erreicht eine Genauigkeit von 76‚ÄØ% und liegt damit deutlich √ºberhalb des klassischen Entscheidungsbaumes ohne Feature-Engineering mit 70%.\n",
    "\n",
    "Klasse 0 (keine KHK) wird mit 73‚ÄØ% Pr√§zision und 72‚ÄØ% Recall erkannt.\n",
    "Klasse 1 (KHK) zeigt mit 78‚ÄØ% Pr√§zision und 78‚ÄØ% Recall eine gute Balance, allerdings auf Kosten einer etwas geringeren Sensitivit√§t im Vergleich zu anderen Modellen.\n",
    "\n",
    "Insgesamt wirkt das Modell instabiler, was bei Entscheidungsb√§umen typisch ist, besonders bei reduzierter Datenkomplexit√§t wie nach PCA:\n",
    "\n",
    "\"Unstable: Decision trees can be unstable, as small changes in the data can result in significant changes to the tree structure.\" (vgl. https://lazyprogrammer.me/mlcompendium/supervised/decision_trees.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Zusammentragung der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of results to a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Sort the DataFrame by accuracy in descending order\n",
    "df_results = df_results.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Optional: Export to Excel\n",
    "# Uncomment the lines below to enable Excel export\n",
    "# df_results.to_excel(\"Modellvergleich.xlsx\", index=False)\n",
    "# display(FileLink(\"Modellvergleich.xlsx\"))\n",
    "\n",
    "# Reorder columns to show 'Model' first\n",
    "df_display = df_results[['Model'] +\n",
    "                        [col for col in df_results.columns if col != 'Model']]\n",
    "\n",
    "# Create table\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=list(df_display.columns),\n",
    "        fill_color='lightblue',\n",
    "        align='left',\n",
    "        font=dict(color='black', size=12)\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[df_display[col] for col in df_display.columns],\n",
    "        fill_color='white',\n",
    "        align='left',\n",
    "        font=dict(color='black', size=11)\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Modellvergleich\",\n",
    "    margin=dict(l=0, r=0, t=40, b=0)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Tabelle zeigt, dass k-NN mit Manhattan-Distanz mit einer Genauigkeit von 86‚ÄØ% am besten abschneidet.\n",
    "Gleichauf liegt das SVM-Modell mit RBF-Kernel, das ebenfalls 86‚ÄØ% erreicht. Beide Modelle √ºberzeugen zus√§tzlich mit hohen F1-Scores in beiden Klassen und weisen eine starke Balance zwischen Pr√§zision und Recall auf.\n",
    "\n",
    "Dicht dahinter folgen AdaBoost mit 85‚ÄØ%, sowie das Stacking-Modell mit 85‚ÄØ%. Auch k-NN mit PCA-Transformation (Manhattan) liegt mit 84‚ÄØ% nur knapp darunter. Wichtig zu erw√§hnen ist hier jedoch, dass die k-NN Variante ohne PCA besser abschneidet (86 %).\n",
    "\n",
    "Weitere Modelle mit sehr soliden Ergebnissen im Bereich von 83 bis 84‚ÄØ% sind das neuronale Netz mit Adam (84‚ÄØ%) und mit SGD-Optimizer (84‚ÄØ%), die sich ebenfalls durch gute F1-Werte auszeichnen.\n",
    "Auch die logistische Regression, das k-NN mit euklidischer Distanz, Minkowski-Distanz (p=3) sowie der Random Forest bewegen sich mit Genauigkeiten zwischen 83 und 84‚ÄØ% im oberen Mittelfeld.\n",
    "\n",
    "Auff√§llig ist, dass alle vier k-NN-Modelle Werte zwischen 83 und 86 % haben, was die Robustheit dieses Verfahrens bei diesem Datensatz unterstreicht.\n",
    "\n",
    "Am unteren Ende des Vergleichs befinden sich die klassischen Entscheidungsb√§ume:\n",
    "Das Modell mit PCA-Vorverarbeitung erreicht 76‚ÄØ%, w√§hrend die Variante ohne PCA lediglich 70‚ÄØ% erzielt. Diese Ergebnisse belegen, dass Entscheidungsb√§ume in ihrer einfachen Form bei diesem Datensatz klar unterlegen sind. Vor allem ohne den Einsatz moderner Ensemble-Methoden wie Boosting oder Bagging wird dieses Ph√§nomen beobachtet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
